{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6acf2682-5cb4-4443-ab3c-7755d90be748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import gc\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async' # to fix GPU issues\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.activations import relu, tanh, linear\n",
    "from tensorflow.keras.utils import Progbar, to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from scipy.signal import butter, lfilter\n",
    "from joblib import Parallel, delayed #Paralleize calculation\n",
    "from sqlalchemy import create_engine, Column, Integer, ARRAY, MetaData, Table, Text, TypeDecorator, LargeBinary, BLOB\n",
    "from sqlalchemy.dialects.postgresql import ARRAY as PG_ARRAY\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras import backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d80e90-046f-4981-9dc4-d10148b2478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WICHTIG!!!\n",
    "database_sqlite3 = False # Set True for sqlite3 and False for postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d19e001-a5ed-4983-93c0-1b5e7e9e5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom adapter function for postgre\n",
    "def adapt_numpy_ndarray(numpy_array):\n",
    "    return AsIs(list(numpy_array))\n",
    "# Register the postgre-adapter\n",
    "register_adapter(np.ndarray, adapt_numpy_ndarray)\n",
    "\n",
    "# Function to convert the mess of an sqlite-BLOB-column\n",
    "def convert_binary_to_array(binary_data):\n",
    "    if binary_data is not None:\n",
    "        out = io.BytesIO(binary_data)\n",
    "        return np.load(out, allow_pickle=True)\n",
    "    return None\n",
    "\n",
    "# Database connection parameters and alchemy engine\n",
    "dbname = 'bathunting'\n",
    "user = 'python'\n",
    "password = 'python_password'\n",
    "host = 'localhost'\n",
    "port = '5432' \n",
    "\n",
    "query_flavour = ''\n",
    "if database_sqlite3:\n",
    "    # sqllite3\n",
    "    engine = create_engine('sqlite:///batcallsv14.db')\n",
    "    table_name = 'batcalls'\n",
    "    array_col = 'arr'\n",
    "else:\n",
    "    #postgres\n",
    "    engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}')\n",
    "    table_name = 'batcall'\n",
    "    array_col = 'new_arr'\n",
    "    query_flavour = '10 < ANY(new_arr) and'\n",
    "\n",
    "def get_target_data(target, limit=0, no_target=False):\n",
    "    lmt = \"\" if limit<=0 else f\"LIMIT {limit}\"\n",
    "    #query = \"\"\n",
    "    if no_target:\n",
    "        query = f\"SELECT {array_col} FROM {table_name} where {query_flavour} target = {target} {lmt}\"\n",
    "    else:\n",
    "        query = f\"SELECT target, {array_col} FROM {table_name} where {query_flavour} target = {target} {lmt}\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    if database_sqlite3:\n",
    "        df['new_arr'] = df['arr'].apply(convert_binary_to_array)\n",
    "        df.drop('arr', axis=1, inplace=True)\n",
    "    if no_target:\n",
    "        df = pd.DataFrame(df['new_arr'].tolist())\n",
    "    return df\n",
    "\n",
    "def get_data(targets=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], limit=0, no_target=False):\n",
    "    all_df = Parallel(n_jobs=-3, prefer=\"threads\")(delayed(get_target_data)(target, limit, no_target) for target in targets)\n",
    "    df = pd.concat(all_df)\n",
    "    return df\n",
    "\n",
    "def get_targets():\n",
    "    #conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    #cursor = conn.cursor()\n",
    "    query = f\"SELECT target, bat FROM {table_name} group by target, bat order by target\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    #conn.close()\n",
    "    return df\n",
    "\n",
    "def get_shape(nested_list):\n",
    "    try:\n",
    "        # Initialize shape list\n",
    "        shape = []\n",
    "        # Iterate to calculate the shape\n",
    "        while isinstance(nested_list, list) or isinstance(nested_list, np.ndarray):\n",
    "            shape.append(len(nested_list))\n",
    "            nested_list = nested_list[0]\n",
    "        return tuple(shape)\n",
    "    except (TypeError, IndexError) as e:\n",
    "        # In case the nested lists are not uniformly sized\n",
    "        return f\"Irregular shape - nested lists are not of equal size. \\n ERROR: {e}\"\n",
    "    \n",
    "# Get data to work with\n",
    "def get_features_and_targets(limit=500, scaler=StandardScaler(), categorical=True):\n",
    "    data = get_data(limit=limit)\n",
    "    df = pd.DataFrame(data[\"new_arr\"].tolist())\n",
    "    if scaler != None:\n",
    "        df = scaler.fit_transform(df)\n",
    "\n",
    "    labels = pd.DataFrame(data[\"target\"])\n",
    "    if categorical:\n",
    "        labels = to_categorical(labels, num_classes=19)\n",
    "    return df, labels\n",
    "\n",
    "def fourie_transformation(df):\n",
    "    data_reshaped = []\n",
    "    for _,data in df.iterrows():\n",
    "        # Normalize\n",
    "        data -= np.mean(data)\n",
    "        data /= np.std(data)\n",
    "        # Realy no idea just assuming prof did it right\n",
    "        # Calculate spectrogram with FFT\n",
    "        stft = np.abs(librosa.stft(np.array(data), n_fft=512, hop_length=32))\n",
    "        stft = 10 * np.log10(stft)\n",
    "        stft = np.nan_to_num(stft)\n",
    "        # Scale between [0,1] and reduce shape if needed\n",
    "        stft = (stft - np.min(stft)) / (np.max(stft) - np.min(stft))\n",
    "        data_reshaped.append(stft.flatten())\n",
    "    return np.array(data_reshaped)\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "  nyq = 0.5 * fs\n",
    "  low = lowcut / nyq\n",
    "  high = highcut / nyq\n",
    "  b, a = butter(order, [low, high], btype='band')\n",
    "  return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "  b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "  y = lfilter(b, a, data)\n",
    "  return y\n",
    "    \n",
    "def bandpass_fourie_transformation(df):\n",
    "    data_reshaped = []\n",
    "    for _,data in df.iterrows():\n",
    "        # Normalize\n",
    "        data = data.astype(np.float32) / 32768.0\n",
    "    \n",
    "        # Bandpass to filter low and high frequencies\n",
    "        data = butter_bandpass_filter(data, 1500, 12000, 44100, 5)\n",
    "        data -= np.mean(data)\n",
    "        data /= np.std(data)\n",
    "        # Realy no idea just assuming prof did it right\n",
    "        # Calculate spectrogram with FFT\n",
    "        stft = np.abs(librosa.stft(np.array(data), n_fft=512, hop_length=32))\n",
    "        stft = 10 * np.log10(stft)\n",
    "        stft = np.nan_to_num(stft)\n",
    "        # Scale between [0,1] and reduce shape if needed\n",
    "        stft = (stft - np.min(stft)) / (np.max(stft) - np.min(stft))\n",
    "        data_reshaped.append(stft.flatten())\n",
    "    return np.array(data_reshaped)\n",
    "\n",
    "def visualize_history(history, title_appendix=''):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy {title_appendix}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(f'History/accuracy_{title_appendix}.png')\n",
    "    plt.close()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss {title_appendix}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(f'History/loss_{title_appendix}.png')\n",
    "    plt.close()\n",
    "\n",
    "def generate_confusion_matrix(X_test, y_test, title_appendix):\n",
    "    # Confusion Matrix\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_test, axis=1)  # y_test are the true labels (one-hot encoded)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Plot the confusion matrix using Seaborn\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.savefig(f'Confusion/ConfusionMatrix_PCA_{title_appendix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b100fc52-63bb-42e1-b810-f07292221477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9067, 35466)\n",
      "(9067, 35466)\n",
      "Number of principal components (plain): 1926\n",
      "Number of principal components (fourie): 5277\n",
      "Number of principal components (fourie & bandpass): 5114\n"
     ]
    }
   ],
   "source": [
    "df, labels = get_features_and_targets(categorical=False)\n",
    "df_fourie = fourie_transformation(pd.DataFrame(df))\n",
    "df_fourie_bandpass = bandpass_fourie_transformation(pd.DataFrame(df))\n",
    "\n",
    "print(df_fourie.shape)\n",
    "print(df_fourie_bandpass.shape)\n",
    "\n",
    "pca = PCA(n_components=0.99)  # You can change the number of components\n",
    "pca_fourie = PCA(n_components=0.99)\n",
    "pca_fourie_bandpass = PCA(n_components=0.99)\n",
    "pca.fit(df)\n",
    "pca_fourie.fit(df_fourie)\n",
    "pca_fourie_bandpass.fit(df_fourie_bandpass)\n",
    "df_pca = pca.transform(df)\n",
    "df_fourie_pca = pca_fourie.transform(df_fourie)\n",
    "df_fourie_bandpass_pca = pca_fourie_bandpass.transform(df_fourie_bandpass)\n",
    "#print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "#print(\"Components:\", pca.components_)\n",
    "print(f'Number of principal components (plain): {len(pca.components_)}')\n",
    "print(f'Number of principal components (fourie): {len(pca_fourie.components_)}')\n",
    "print(f'Number of principal components (fourie & bandpass): {len(pca_fourie_bandpass.components_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3ffbc-e52b-44c5-b2f4-c414f5cdcb46",
   "metadata": {},
   "source": [
    "Die Features scheinen nach der Fourie-Trasnsformation und auch durch das Noize-Filtering schwerer durch die PCA beschrieben werden zu können als die unverarbeiteten Daten. (Es werden mehr principal components benötigt um die Varianz in den Daten zu 99% erklären zu können)\n",
    "\n",
    "PS: Die CPU hasst das ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f52eb1-bb30-4673-9238-2c825a270cf4",
   "metadata": {},
   "source": [
    "## Neuronal Network\n",
    "\n",
    "Wie gut lassen sich die Fledermäuse klassifizieren? Zu Beginn wird mit einem sehr simplen Neuronalen Netzwerk getestet wobei die Anzahl der Neuronen variiert wird. Dies wird sowohl für die Rohdaten, die nur mit der Fourie-Transformation vorverarbeiteten Daten als auch für die zusätzlich gefilterten Daten getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3dae230-b290-4126-b7df-8f347a7f3782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:14:29.717690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1c9c0088f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-17 10:14:29.717745: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-01-17 10:14:29.728660: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-17 10:14:29.863727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2024-01-17 10:14:29.954648: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 8.3054 - accuracy: 0.3219\n",
      "Density: 50\n",
      "Final Training Loss: 3.959172772738384e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.928843021392822\n",
      "Final Validation Accuracy: 0.3535492718219757\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.5931 - accuracy: 0.3611\n",
      "Density: 100\n",
      "Final Training Loss: 2.7532153126230696e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 6.4291768074035645\n",
      "Final Validation Accuracy: 0.3687112331390381\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.4427 - accuracy: 0.3666\n",
      "Density: 150\n",
      "Final Training Loss: 2.312478500243742e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 6.256906032562256\n",
      "Final Validation Accuracy: 0.3756030201911926\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.6150 - accuracy: 0.3671\n",
      "Density: 200\n",
      "Final Training Loss: 2.051109959211317e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 6.519431114196777\n",
      "Final Validation Accuracy: 0.3818056583404541\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.8487 - accuracy: 0.3754\n",
      "Density: 250\n",
      "Final Training Loss: 1.7821803339757025e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 6.512040615081787\n",
      "Final Validation Accuracy: 0.3949000835418701\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.0630 - accuracy: 0.3638\n",
      "Density: 300\n",
      "Final Training Loss: 1.6196596561712795e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 6.827082633972168\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.9736 - accuracy: 0.3776\n",
      "Density: 350\n",
      "Final Training Loss: 1.5242223980749259e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 6.785499572753906\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.4564 - accuracy: 0.3671\n",
      "Density: 400\n",
      "Final Training Loss: 1.373248665004212e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.153436183929443\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.4953 - accuracy: 0.3754\n",
      "Density: 450\n",
      "Final Training Loss: 1.3141782346792752e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.478399753570557\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.6942 - accuracy: 0.3738\n",
      "Density: 500\n",
      "Final Training Loss: 1.1982770047325175e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.5098748207092285\n",
      "Final Validation Accuracy: 0.39283251762390137\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.8847 - accuracy: 0.3771\n",
      "Density: 550\n",
      "Final Training Loss: 1.1110581681350595e-06\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.448641777038574\n",
      "Final Validation Accuracy: 0.3893866240978241\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.0938 - accuracy: 0.3804\n",
      "Density: 600\n",
      "Final Training Loss: 9.957732345355907e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.713906764984131\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.1690 - accuracy: 0.3440\n",
      "Density: 650\n",
      "Final Training Loss: 8.790501055955247e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 8.26591682434082\n",
      "Final Validation Accuracy: 0.396278440952301\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.7632 - accuracy: 0.3666\n",
      "Density: 700\n",
      "Final Training Loss: 8.344235880031192e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 8.6451997756958\n",
      "Final Validation Accuracy: 0.3756030201911926\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.7048 - accuracy: 0.3749\n",
      "Density: 750\n",
      "Final Training Loss: 8.072409514170431e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 8.542585372924805\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.2864 - accuracy: 0.3616\n",
      "Density: 800\n",
      "Final Training Loss: 7.356579203587899e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.105897903442383\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.5831 - accuracy: 0.3633\n",
      "Density: 850\n",
      "Final Training Loss: 6.476583962466975e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.339849472045898\n",
      "Final Validation Accuracy: 0.38387319445610046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.0692 - accuracy: 0.3760\n",
      "Density: 900\n",
      "Final Training Loss: 6.731974053764134e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 8.731400489807129\n",
      "Final Validation Accuracy: 0.38869744539260864\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.5350 - accuracy: 0.3666\n",
      "Density: 950\n",
      "Final Training Loss: 6.042442350917554e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.374227523803711\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.7573 - accuracy: 0.3782\n",
      "Density: 1000\n",
      "Final Training Loss: 5.731782835027843e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.610455513000488\n",
      "Final Validation Accuracy: 0.38731908798217773\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.3829 - accuracy: 0.3589\n",
      "Density: 1050\n",
      "Final Training Loss: 5.402426950240624e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.024306297302246\n",
      "Final Validation Accuracy: 0.38869744539260864\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.4890 - accuracy: 0.3677\n",
      "Density: 1100\n",
      "Final Training Loss: 4.569687916955445e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 10.207327842712402\n",
      "Final Validation Accuracy: 0.37973812222480774\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.8354 - accuracy: 0.3738\n",
      "Density: 1150\n",
      "Final Training Loss: 3.877895835557865e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 10.587261199951172\n",
      "Final Validation Accuracy: 0.37973812222480774\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.0997 - accuracy: 0.3738\n",
      "Density: 1200\n",
      "Final Training Loss: 4.272589535503357e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.77363109588623\n",
      "Final Validation Accuracy: 0.403859406709671\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.0317 - accuracy: 0.3804\n",
      "Density: 1250\n",
      "Final Training Loss: 3.7611937386827776e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 10.239089965820312\n",
      "Final Validation Accuracy: 0.3845623731613159\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.0779 - accuracy: 0.3782\n",
      "Density: 1300\n",
      "Final Training Loss: 3.4143729976676696e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 10.631478309631348\n",
      "Final Validation Accuracy: 0.37698137760162354\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.4426 - accuracy: 0.3660\n",
      "Density: 1350\n",
      "Final Training Loss: 3.461013591277151e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 10.683868408203125\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.1020 - accuracy: 0.3782\n",
      "Density: 1400\n",
      "Final Training Loss: 3.2072676958705415e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 10.766037940979004\n",
      "Final Validation Accuracy: 0.38525155186653137\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12.0238 - accuracy: 0.3771\n",
      "Density: 1450\n",
      "Final Training Loss: 2.46349344479313e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.234882354736328\n",
      "Final Validation Accuracy: 0.37973812222480774\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.8132 - accuracy: 0.3716\n",
      "Density: 1500\n",
      "Final Training Loss: 2.2759064677302376e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.12769603729248\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12.3145 - accuracy: 0.3660\n",
      "Density: 1550\n",
      "Final Training Loss: 2.303232946587741e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 11.517693519592285\n",
      "Final Validation Accuracy: 0.3845623731613159\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12.7674 - accuracy: 0.3644\n",
      "Density: 1600\n",
      "Final Training Loss: 2.024831218250256e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.70654010772705\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 12.8206 - accuracy: 0.3622\n",
      "Density: 1650\n",
      "Final Training Loss: 2.0174347525880876e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.79094409942627\n",
      "Final Validation Accuracy: 0.3749138414859772\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12.9802 - accuracy: 0.3561\n",
      "Density: 1700\n",
      "Final Training Loss: 1.7449916356326867e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.638633728027344\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 13.3225 - accuracy: 0.3627\n",
      "Density: 1750\n",
      "Final Training Loss: 1.5956204890699155e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.800559043884277\n",
      "Final Validation Accuracy: 0.37835976481437683\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 13.2198 - accuracy: 0.3655\n",
      "Density: 1800\n",
      "Final Training Loss: 1.5493915839215333e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 12.839696884155273\n",
      "Final Validation Accuracy: 0.38387319445610046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 13.7498 - accuracy: 0.3627\n",
      "Density: 1850\n",
      "Final Training Loss: 1.4026913675024844e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 13.184290885925293\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 14.2968 - accuracy: 0.3693\n",
      "Density: 1900\n",
      "Final Training Loss: 1.2736607857277704e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 14.097089767456055\n",
      "Final Validation Accuracy: 0.3921433389186859\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 13.7050 - accuracy: 0.3699\n",
      "Density: 1950\n",
      "Final Training Loss: 1.2294864859541121e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 13.170138359069824\n",
      "Final Validation Accuracy: 0.38387319445610046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 14.3369 - accuracy: 0.3644\n",
      "Density: 2000\n",
      "Final Training Loss: 1.1111403352970228e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 14.411197662353516\n",
      "Final Validation Accuracy: 0.3804273009300232\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.4388 - accuracy: 0.3264\n",
      "Density: 50\n",
      "Final Training Loss: 7.060920097501366e-07\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 9.14901065826416\n",
      "Final Validation Accuracy: 0.34872502088546753\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.8667 - accuracy: 0.3556\n",
      "Density: 100\n",
      "Final Training Loss: 4.150340515707285e-08\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 7.296889781951904\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 15.5652 - accuracy: 0.3451\n",
      "Density: 150\n",
      "Final Training Loss: 0.03369642794132233\n",
      "Final Training Accuracy: 0.9906928539276123\n",
      "Final Validation Loss: 14.46226978302002\n",
      "Final Validation Accuracy: 0.36181944608688354\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 17.4670 - accuracy: 0.3545\n",
      "Density: 200\n",
      "Final Training Loss: 0.08135203272104263\n",
      "Final Training Accuracy: 0.986901044845581\n",
      "Final Validation Loss: 17.53717613220215\n",
      "Final Validation Accuracy: 0.36595451831817627\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 19.5217 - accuracy: 0.3561\n",
      "Density: 250\n",
      "Final Training Loss: 0.07155302911996841\n",
      "Final Training Accuracy: 0.9884522557258606\n",
      "Final Validation Loss: 19.132814407348633\n",
      "Final Validation Accuracy: 0.3762921988964081\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 22.1629 - accuracy: 0.3495\n",
      "Density: 300\n",
      "Final Training Loss: 0.0443047471344471\n",
      "Final Training Accuracy: 0.988624632358551\n",
      "Final Validation Loss: 21.48748016357422\n",
      "Final Validation Accuracy: 0.36181944608688354\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 24.4843 - accuracy: 0.3600\n",
      "Density: 350\n",
      "Final Training Loss: 0.0878414586186409\n",
      "Final Training Accuracy: 0.9836263060569763\n",
      "Final Validation Loss: 22.960739135742188\n",
      "Final Validation Accuracy: 0.3866299092769623\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 26.0665 - accuracy: 0.3545\n",
      "Density: 400\n",
      "Final Training Loss: 0.07321438193321228\n",
      "Final Training Accuracy: 0.988624632358551\n",
      "Final Validation Loss: 24.800434112548828\n",
      "Final Validation Accuracy: 0.36044108867645264\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 28.1776 - accuracy: 0.3776\n",
      "Density: 450\n",
      "Final Training Loss: 0.07672730088233948\n",
      "Final Training Accuracy: 0.9917269945144653\n",
      "Final Validation Loss: 27.270851135253906\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 32.5160 - accuracy: 0.3501\n",
      "Density: 500\n",
      "Final Training Loss: 0.14882662892341614\n",
      "Final Training Accuracy: 0.9834539890289307\n",
      "Final Validation Loss: 32.05866622924805\n",
      "Final Validation Accuracy: 0.3666436970233917\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 33.3303 - accuracy: 0.3721\n",
      "Density: 550\n",
      "Final Training Loss: 0.13711322844028473\n",
      "Final Training Accuracy: 0.986901044845581\n",
      "Final Validation Loss: 30.9012393951416\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 36.3301 - accuracy: 0.3600\n",
      "Density: 600\n",
      "Final Training Loss: 0.13523535430431366\n",
      "Final Training Accuracy: 0.9874181151390076\n",
      "Final Validation Loss: 34.75416946411133\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 40.1336 - accuracy: 0.3666\n",
      "Density: 650\n",
      "Final Training Loss: 0.10687204450368881\n",
      "Final Training Accuracy: 0.9879351854324341\n",
      "Final Validation Loss: 36.822044372558594\n",
      "Final Validation Accuracy: 0.3935216963291168\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 40.8377 - accuracy: 0.3776\n",
      "Density: 700\n",
      "Final Training Loss: 0.12177683413028717\n",
      "Final Training Accuracy: 0.9872457981109619\n",
      "Final Validation Loss: 40.9752311706543\n",
      "Final Validation Accuracy: 0.40179187059402466\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 43.5964 - accuracy: 0.3638\n",
      "Density: 750\n",
      "Final Training Loss: 0.1907660812139511\n",
      "Final Training Accuracy: 0.9850051999092102\n",
      "Final Validation Loss: 42.87176513671875\n",
      "Final Validation Accuracy: 0.390764981508255\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 45.4111 - accuracy: 0.3732\n",
      "Density: 800\n",
      "Final Training Loss: 0.10998979210853577\n",
      "Final Training Accuracy: 0.9887969493865967\n",
      "Final Validation Loss: 43.959495544433594\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 45.5091 - accuracy: 0.3815\n",
      "Density: 850\n",
      "Final Training Loss: 0.1656288504600525\n",
      "Final Training Accuracy: 0.986901044845581\n",
      "Final Validation Loss: 47.15498352050781\n",
      "Final Validation Accuracy: 0.38111647963523865\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 50.1853 - accuracy: 0.3677\n",
      "Density: 900\n",
      "Final Training Loss: 0.11296282708644867\n",
      "Final Training Accuracy: 0.988624632358551\n",
      "Final Validation Loss: 47.4409294128418\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 51.1145 - accuracy: 0.3743\n",
      "Density: 950\n",
      "Final Training Loss: 0.1503673940896988\n",
      "Final Training Accuracy: 0.9882798790931702\n",
      "Final Validation Loss: 49.66950988769531\n",
      "Final Validation Accuracy: 0.3866299092769623\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 56.7921 - accuracy: 0.3655\n",
      "Density: 1000\n",
      "Final Training Loss: 0.19892454147338867\n",
      "Final Training Accuracy: 0.9856945872306824\n",
      "Final Validation Loss: 53.829017639160156\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 57.4124 - accuracy: 0.3754\n",
      "Density: 1050\n",
      "Final Training Loss: 0.2534704804420471\n",
      "Final Training Accuracy: 0.9839710593223572\n",
      "Final Validation Loss: 55.32101821899414\n",
      "Final Validation Accuracy: 0.3969676196575165\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 61.7380 - accuracy: 0.3716\n",
      "Density: 1100\n",
      "Final Training Loss: 0.20873281359672546\n",
      "Final Training Accuracy: 0.9870734214782715\n",
      "Final Validation Loss: 60.579345703125\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 62.2212 - accuracy: 0.3782\n",
      "Density: 1150\n",
      "Final Training Loss: 0.12179172784090042\n",
      "Final Training Accuracy: 0.9905205368995667\n",
      "Final Validation Loss: 62.064151763916016\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 64.4016 - accuracy: 0.3677\n",
      "Density: 1200\n",
      "Final Training Loss: 0.12556400895118713\n",
      "Final Training Accuracy: 0.9908652305603027\n",
      "Final Validation Loss: 61.42182540893555\n",
      "Final Validation Accuracy: 0.3935216963291168\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 67.1299 - accuracy: 0.3738\n",
      "Density: 1250\n",
      "Final Training Loss: 0.3051479160785675\n",
      "Final Training Accuracy: 0.9855222105979919\n",
      "Final Validation Loss: 65.76757049560547\n",
      "Final Validation Accuracy: 0.3921433389186859\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 68.0777 - accuracy: 0.3660\n",
      "Density: 1300\n",
      "Final Training Loss: 0.23667512834072113\n",
      "Final Training Accuracy: 0.9882798790931702\n",
      "Final Validation Loss: 65.32429504394531\n",
      "Final Validation Accuracy: 0.3935216963291168\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 71.7769 - accuracy: 0.3809\n",
      "Density: 1350\n",
      "Final Training Loss: 0.30988872051239014\n",
      "Final Training Accuracy: 0.9844881296157837\n",
      "Final Validation Loss: 69.18889617919922\n",
      "Final Validation Accuracy: 0.3942108750343323\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 73.3845 - accuracy: 0.3727\n",
      "Density: 1400\n",
      "Final Training Loss: 0.2801533341407776\n",
      "Final Training Accuracy: 0.9843157529830933\n",
      "Final Validation Loss: 73.22850036621094\n",
      "Final Validation Accuracy: 0.3762921988964081\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 76.7657 - accuracy: 0.3693\n",
      "Density: 1450\n",
      "Final Training Loss: 0.4037151336669922\n",
      "Final Training Accuracy: 0.9827645421028137\n",
      "Final Validation Loss: 75.55794525146484\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 83.3259 - accuracy: 0.3622\n",
      "Density: 1500\n",
      "Final Training Loss: 0.413271427154541\n",
      "Final Training Accuracy: 0.9831092953681946\n",
      "Final Validation Loss: 79.6691665649414\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 81.1552 - accuracy: 0.3688\n",
      "Density: 1550\n",
      "Final Training Loss: 0.334346204996109\n",
      "Final Training Accuracy: 0.9837986826896667\n",
      "Final Validation Loss: 81.51239776611328\n",
      "Final Validation Accuracy: 0.38249483704566956\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 83.8011 - accuracy: 0.3804\n",
      "Density: 1600\n",
      "Final Training Loss: 0.23531357944011688\n",
      "Final Training Accuracy: 0.9874181151390076\n",
      "Final Validation Loss: 80.88499450683594\n",
      "Final Validation Accuracy: 0.3949000835418701\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 84.5146 - accuracy: 0.3710\n",
      "Density: 1650\n",
      "Final Training Loss: 0.2507109045982361\n",
      "Final Training Accuracy: 0.9863840341567993\n",
      "Final Validation Loss: 83.34664916992188\n",
      "Final Validation Accuracy: 0.3949000835418701\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 87.6903 - accuracy: 0.3738\n",
      "Density: 1700\n",
      "Final Training Loss: 0.2829308807849884\n",
      "Final Training Accuracy: 0.9903481602668762\n",
      "Final Validation Loss: 81.51532745361328\n",
      "Final Validation Accuracy: 0.390764981508255\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 89.7336 - accuracy: 0.3771\n",
      "Density: 1750\n",
      "Final Training Loss: 0.45280805230140686\n",
      "Final Training Accuracy: 0.9824198484420776\n",
      "Final Validation Loss: 87.42545318603516\n",
      "Final Validation Accuracy: 0.390764981508255\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 94.7563 - accuracy: 0.3815\n",
      "Density: 1800\n",
      "Final Training Loss: 0.2973526120185852\n",
      "Final Training Accuracy: 0.9884522557258606\n",
      "Final Validation Loss: 88.65113830566406\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 95.0824 - accuracy: 0.3815\n",
      "Density: 1850\n",
      "Final Training Loss: 0.43678513169288635\n",
      "Final Training Accuracy: 0.9862116575241089\n",
      "Final Validation Loss: 92.70381164550781\n",
      "Final Validation Accuracy: 0.40179187059402466\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 100.4006 - accuracy: 0.3699\n",
      "Density: 1900\n",
      "Final Training Loss: 0.2880490720272064\n",
      "Final Training Accuracy: 0.9872457981109619\n",
      "Final Validation Loss: 97.44764709472656\n",
      "Final Validation Accuracy: 0.3969676196575165\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 101.2722 - accuracy: 0.3705\n",
      "Density: 1950\n",
      "Final Training Loss: 0.3456825613975525\n",
      "Final Training Accuracy: 0.9858669638633728\n",
      "Final Validation Loss: 99.4743423461914\n",
      "Final Validation Accuracy: 0.3935216963291168\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 104.2936 - accuracy: 0.3600\n",
      "Density: 2000\n",
      "Final Training Loss: 0.3564085364341736\n",
      "Final Training Accuracy: 0.9851775169372559\n",
      "Final Validation Loss: 101.86381530761719\n",
      "Final Validation Accuracy: 0.37698137760162354\n"
     ]
    }
   ],
   "source": [
    "# Tests with the plain pca data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "# Density 50 to 2000\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(50, 2001, 50):\n",
    "        title_appendix = f'd{i}'\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(i, activation='relu'))\n",
    "        model.add(Dense(19, activation='softmax'))\n",
    "    \n",
    "        # Compile the model\n",
    "        optimizer=RMSprop(learning_rate=0.001)\n",
    "        if opti == 'ADAM':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        # Fit the model\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2)\n",
    "    \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('Density: %.i' % (i))\n",
    "        print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "        print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "        print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "        print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "        visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "\n",
    "        # Clear Keras session\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbfd8cb-ba48-4621-a8db-8fe333a9a482",
   "metadata": {},
   "source": [
    "Wie man in den zugehörigen Graphen schön sehen kann findet sehr schnell (bereits vor der 5. Epoche) Overfitting statt unabhängig von der Anzahl der Neuronen. Der Durchlauf wird daher mit early Stopping wiederholt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c5fef9-546b-47ce-a154-2ec156ee63ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.9745 - accuracy: 0.3280\n",
      "Density: 50\n",
      "Final Training Loss: 0.05138752609491348\n",
      "Final Training Accuracy: 0.987590491771698\n",
      "Final Validation Loss: 4.871613025665283\n",
      "Final Validation Accuracy: 0.35148173570632935\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.1549 - accuracy: 0.3418\n",
      "Density: 100\n",
      "Final Training Loss: 0.018845876678824425\n",
      "Final Training Accuracy: 0.9956911206245422\n",
      "Final Validation Loss: 4.9424943923950195\n",
      "Final Validation Accuracy: 0.3652653396129608\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.3053 - accuracy: 0.3423\n",
      "Density: 150\n",
      "Final Training Loss: 0.02094409614801407\n",
      "Final Training Accuracy: 0.9931058287620544\n",
      "Final Validation Loss: 4.9713287353515625\n",
      "Final Validation Accuracy: 0.3728463053703308\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.2438 - accuracy: 0.3523\n",
      "Density: 200\n",
      "Final Training Loss: 0.022687328979372978\n",
      "Final Training Accuracy: 0.9931058287620544\n",
      "Final Validation Loss: 4.967051982879639\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.3063 - accuracy: 0.3820\n",
      "Density: 250\n",
      "Final Training Loss: 0.02734394744038582\n",
      "Final Training Accuracy: 0.9918993711471558\n",
      "Final Validation Loss: 5.144067287445068\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.4692 - accuracy: 0.3638\n",
      "Density: 300\n",
      "Final Training Loss: 0.029557032510638237\n",
      "Final Training Accuracy: 0.9903481602668762\n",
      "Final Validation Loss: 5.299883842468262\n",
      "Final Validation Accuracy: 0.3859407305717468\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.5707 - accuracy: 0.3545\n",
      "Density: 350\n",
      "Final Training Loss: 0.043652281165122986\n",
      "Final Training Accuracy: 0.9860392808914185\n",
      "Final Validation Loss: 5.567414283752441\n",
      "Final Validation Accuracy: 0.362508624792099\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.7064 - accuracy: 0.3594\n",
      "Density: 400\n",
      "Final Training Loss: 0.04934665188193321\n",
      "Final Training Accuracy: 0.9829369187355042\n",
      "Final Validation Loss: 5.5753960609436035\n",
      "Final Validation Accuracy: 0.3756030201911926\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.8967 - accuracy: 0.3578\n",
      "Density: 450\n",
      "Final Training Loss: 0.0523863360285759\n",
      "Final Training Accuracy: 0.9831092953681946\n",
      "Final Validation Loss: 5.75452184677124\n",
      "Final Validation Accuracy: 0.37698137760162354\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.0537 - accuracy: 0.3572\n",
      "Density: 500\n",
      "Final Training Loss: 0.053574465215206146\n",
      "Final Training Accuracy: 0.9843157529830933\n",
      "Final Validation Loss: 5.8643269538879395\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.2224 - accuracy: 0.3600\n",
      "Density: 550\n",
      "Final Training Loss: 0.06422491371631622\n",
      "Final Training Accuracy: 0.9800068736076355\n",
      "Final Validation Loss: 5.9676103591918945\n",
      "Final Validation Accuracy: 0.3893866240978241\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.0030 - accuracy: 0.3738\n",
      "Density: 600\n",
      "Final Training Loss: 0.07332699000835419\n",
      "Final Training Accuracy: 0.9789727926254272\n",
      "Final Validation Loss: 5.8074164390563965\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.0245 - accuracy: 0.3716\n",
      "Density: 650\n",
      "Final Training Loss: 0.08416414260864258\n",
      "Final Training Accuracy: 0.9753533005714417\n",
      "Final Validation Loss: 6.022676944732666\n",
      "Final Validation Accuracy: 0.3776705861091614\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.0641 - accuracy: 0.3705\n",
      "Density: 700\n",
      "Final Training Loss: 0.08059888333082199\n",
      "Final Training Accuracy: 0.9760427474975586\n",
      "Final Validation Loss: 5.796082973480225\n",
      "Final Validation Accuracy: 0.39007580280303955\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.4999 - accuracy: 0.3693\n",
      "Density: 750\n",
      "Final Training Loss: 0.06860127300024033\n",
      "Final Training Accuracy: 0.9779386520385742\n",
      "Final Validation Loss: 6.25222635269165\n",
      "Final Validation Accuracy: 0.38249483704566956\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.4342 - accuracy: 0.3578\n",
      "Density: 800\n",
      "Final Training Loss: 0.09265176951885223\n",
      "Final Training Accuracy: 0.969148576259613\n",
      "Final Validation Loss: 6.255528450012207\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.5370 - accuracy: 0.3649\n",
      "Density: 850\n",
      "Final Training Loss: 0.11799515038728714\n",
      "Final Training Accuracy: 0.9632885456085205\n",
      "Final Validation Loss: 6.408593654632568\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.7513 - accuracy: 0.3710\n",
      "Density: 900\n",
      "Final Training Loss: 0.11176320910453796\n",
      "Final Training Accuracy: 0.9682868123054504\n",
      "Final Validation Loss: 6.487296104431152\n",
      "Final Validation Accuracy: 0.37698137760162354\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.7746 - accuracy: 0.3660\n",
      "Density: 950\n",
      "Final Training Loss: 0.11896098405122757\n",
      "Final Training Accuracy: 0.9641503095626831\n",
      "Final Validation Loss: 6.607995986938477\n",
      "Final Validation Accuracy: 0.3880082666873932\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.9989 - accuracy: 0.3649\n",
      "Density: 1000\n",
      "Final Training Loss: 0.12869417667388916\n",
      "Final Training Accuracy: 0.9643226265907288\n",
      "Final Validation Loss: 6.806310653686523\n",
      "Final Validation Accuracy: 0.3818056583404541\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.2795 - accuracy: 0.3655\n",
      "Density: 1050\n",
      "Final Training Loss: 0.12555012106895447\n",
      "Final Training Accuracy: 0.9625990986824036\n",
      "Final Validation Loss: 7.049001693725586\n",
      "Final Validation Accuracy: 0.3749138414859772\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.3637 - accuracy: 0.3649\n",
      "Density: 1100\n",
      "Final Training Loss: 0.1424417495727539\n",
      "Final Training Accuracy: 0.9615649580955505\n",
      "Final Validation Loss: 6.8510518074035645\n",
      "Final Validation Accuracy: 0.390764981508255\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.2317 - accuracy: 0.3561\n",
      "Density: 1150\n",
      "Final Training Loss: 0.14267559349536896\n",
      "Final Training Accuracy: 0.955704927444458\n",
      "Final Validation Loss: 6.985745906829834\n",
      "Final Validation Accuracy: 0.3666436970233917\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.2003 - accuracy: 0.3710\n",
      "Density: 1200\n",
      "Final Training Loss: 0.15333706140518188\n",
      "Final Training Accuracy: 0.9579455256462097\n",
      "Final Validation Loss: 6.919378757476807\n",
      "Final Validation Accuracy: 0.3742246627807617\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.2026 - accuracy: 0.3600\n",
      "Density: 1250\n",
      "Final Training Loss: 0.14439444243907928\n",
      "Final Training Accuracy: 0.9603585004806519\n",
      "Final Validation Loss: 7.045494079589844\n",
      "Final Validation Accuracy: 0.37973812222480774\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.2619 - accuracy: 0.3749\n",
      "Density: 1300\n",
      "Final Training Loss: 0.13412389159202576\n",
      "Final Training Accuracy: 0.9615649580955505\n",
      "Final Validation Loss: 6.838130950927734\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.3856 - accuracy: 0.3660\n",
      "Density: 1350\n",
      "Final Training Loss: 0.15100957453250885\n",
      "Final Training Accuracy: 0.9588072896003723\n",
      "Final Validation Loss: 6.9989399909973145\n",
      "Final Validation Accuracy: 0.3818056583404541\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.3974 - accuracy: 0.3671\n",
      "Density: 1400\n",
      "Final Training Loss: 0.1713220179080963\n",
      "Final Training Accuracy: 0.9519131183624268\n",
      "Final Validation Loss: 7.15087366104126\n",
      "Final Validation Accuracy: 0.38525155186653137\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.7573 - accuracy: 0.3655\n",
      "Density: 1450\n",
      "Final Training Loss: 0.21057143807411194\n",
      "Final Training Accuracy: 0.9453636407852173\n",
      "Final Validation Loss: 7.5869598388671875\n",
      "Final Validation Accuracy: 0.3742246627807617\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.6286 - accuracy: 0.3677\n",
      "Density: 1500\n",
      "Final Training Loss: 0.1867065280675888\n",
      "Final Training Accuracy: 0.9526025652885437\n",
      "Final Validation Loss: 7.376784801483154\n",
      "Final Validation Accuracy: 0.3942108750343323\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.3423 - accuracy: 0.3545\n",
      "Density: 1550\n",
      "Final Training Loss: 0.18733537197113037\n",
      "Final Training Accuracy: 0.9489831328392029\n",
      "Final Validation Loss: 7.942520618438721\n",
      "Final Validation Accuracy: 0.3728463053703308\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.4051 - accuracy: 0.3578\n",
      "Density: 1600\n",
      "Final Training Loss: 0.20200030505657196\n",
      "Final Training Accuracy: 0.948638379573822\n",
      "Final Validation Loss: 7.9969658851623535\n",
      "Final Validation Accuracy: 0.3756030201911926\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.8427 - accuracy: 0.3671\n",
      "Density: 1650\n",
      "Final Training Loss: 0.23475463688373566\n",
      "Final Training Accuracy: 0.9410548210144043\n",
      "Final Validation Loss: 7.5147929191589355\n",
      "Final Validation Accuracy: 0.383184015750885\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.1151 - accuracy: 0.3638\n",
      "Density: 1700\n",
      "Final Training Loss: 0.21728934347629547\n",
      "Final Training Accuracy: 0.9465701580047607\n",
      "Final Validation Loss: 7.819063186645508\n",
      "Final Validation Accuracy: 0.3652653396129608\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.0943 - accuracy: 0.3716\n",
      "Density: 1750\n",
      "Final Training Loss: 0.20434442162513733\n",
      "Final Training Accuracy: 0.9476042985916138\n",
      "Final Validation Loss: 7.760495662689209\n",
      "Final Validation Accuracy: 0.37698137760162354\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.4619 - accuracy: 0.3467\n",
      "Density: 1800\n",
      "Final Training Loss: 0.2312840074300766\n",
      "Final Training Accuracy: 0.9427783489227295\n",
      "Final Validation Loss: 7.969783306121826\n",
      "Final Validation Accuracy: 0.36595451831817627\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.1340 - accuracy: 0.3693\n",
      "Density: 1850\n",
      "Final Training Loss: 0.2732885181903839\n",
      "Final Training Accuracy: 0.9358841776847839\n",
      "Final Validation Loss: 7.836359024047852\n",
      "Final Validation Accuracy: 0.38111647963523865\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.0164 - accuracy: 0.3666\n",
      "Density: 1900\n",
      "Final Training Loss: 0.2340502142906189\n",
      "Final Training Accuracy: 0.9439848065376282\n",
      "Final Validation Loss: 7.937891006469727\n",
      "Final Validation Accuracy: 0.3714679479598999\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.4902 - accuracy: 0.3517\n",
      "Density: 1950\n",
      "Final Training Loss: 0.24294108152389526\n",
      "Final Training Accuracy: 0.9488107562065125\n",
      "Final Validation Loss: 8.197159767150879\n",
      "Final Validation Accuracy: 0.35561680793762207\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.1786 - accuracy: 0.3693\n",
      "Density: 2000\n",
      "Final Training Loss: 0.27568283677101135\n",
      "Final Training Accuracy: 0.9395036101341248\n",
      "Final Validation Loss: 7.645152568817139\n",
      "Final Validation Accuracy: 0.39145416021347046\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.8868 - accuracy: 0.3258\n",
      "Density: 50\n",
      "Final Training Loss: 0.030247535556554794\n",
      "Final Training Accuracy: 0.997931718826294\n",
      "Final Validation Loss: 3.754211902618408\n",
      "Final Validation Accuracy: 0.3507925570011139\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3750 - accuracy: 0.3627\n",
      "Density: 100\n",
      "Final Training Loss: 0.025174014270305634\n",
      "Final Training Accuracy: 0.9955188035964966\n",
      "Final Validation Loss: 3.2258410453796387\n",
      "Final Validation Accuracy: 0.3749138414859772\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3042 - accuracy: 0.3776\n",
      "Density: 150\n",
      "Final Training Loss: 0.053910065442323685\n",
      "Final Training Accuracy: 0.9894863963127136\n",
      "Final Validation Loss: 3.1742184162139893\n",
      "Final Validation Accuracy: 0.3804273009300232\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.7976 - accuracy: 0.3501\n",
      "Density: 200\n",
      "Final Training Loss: 0.1548570990562439\n",
      "Final Training Accuracy: 0.9589796662330627\n",
      "Final Validation Loss: 3.569192886352539\n",
      "Final Validation Accuracy: 0.3687112331390381\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.4034 - accuracy: 0.3264\n",
      "Density: 250\n",
      "Final Training Loss: 0.44577711820602417\n",
      "Final Training Accuracy: 0.8903826475143433\n",
      "Final Validation Loss: 5.266119956970215\n",
      "Final Validation Accuracy: 0.3342522382736206\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.3156 - accuracy: 0.3456\n",
      "Density: 300\n",
      "Final Training Loss: 0.2717576026916504\n",
      "Final Training Accuracy: 0.9317476749420166\n",
      "Final Validation Loss: 4.188241004943848\n",
      "Final Validation Accuracy: 0.362508624792099\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.4151 - accuracy: 0.3297\n",
      "Density: 350\n",
      "Final Training Loss: 0.2897457480430603\n",
      "Final Training Accuracy: 0.9291623830795288\n",
      "Final Validation Loss: 4.2666192054748535\n",
      "Final Validation Accuracy: 0.35286009311676025\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.7723 - accuracy: 0.3572\n",
      "Density: 400\n",
      "Final Training Loss: 0.4430256187915802\n",
      "Final Training Accuracy: 0.8946914672851562\n",
      "Final Validation Loss: 4.660521507263184\n",
      "Final Validation Accuracy: 0.362508624792099\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.3165 - accuracy: 0.3324\n",
      "Density: 450\n",
      "Final Training Loss: 0.5080721974372864\n",
      "Final Training Accuracy: 0.8814201951026917\n",
      "Final Validation Loss: 5.196446418762207\n",
      "Final Validation Accuracy: 0.3563059866428375\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.7643 - accuracy: 0.3567\n",
      "Density: 500\n",
      "Final Training Loss: 0.7640653252601624\n",
      "Final Training Accuracy: 0.8343674540519714\n",
      "Final Validation Loss: 5.613313674926758\n",
      "Final Validation Accuracy: 0.38387319445610046\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.6116 - accuracy: 0.3363\n",
      "Density: 550\n",
      "Final Training Loss: 0.723386287689209\n",
      "Final Training Accuracy: 0.8390210270881653\n",
      "Final Validation Loss: 5.640849590301514\n",
      "Final Validation Accuracy: 0.33218470215797424\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.9892 - accuracy: 0.3385\n",
      "Density: 600\n",
      "Final Training Loss: 0.9023036956787109\n",
      "Final Training Accuracy: 0.8090313673019409\n",
      "Final Validation Loss: 6.066768169403076\n",
      "Final Validation Accuracy: 0.3473466634750366\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.2075 - accuracy: 0.3451\n",
      "Density: 650\n",
      "Final Training Loss: 1.0185165405273438\n",
      "Final Training Accuracy: 0.7933471202850342\n",
      "Final Validation Loss: 6.2238335609436035\n",
      "Final Validation Accuracy: 0.3480358421802521\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.3517 - accuracy: 0.3451\n",
      "Density: 700\n",
      "Final Training Loss: 0.9523090124130249\n",
      "Final Training Accuracy: 0.8081696033477783\n",
      "Final Validation Loss: 6.1419548988342285\n",
      "Final Validation Accuracy: 0.3597519099712372\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.7357 - accuracy: 0.3219\n",
      "Density: 750\n",
      "Final Training Loss: 1.0194951295852661\n",
      "Final Training Accuracy: 0.7945535778999329\n",
      "Final Validation Loss: 6.412489414215088\n",
      "Final Validation Accuracy: 0.3611302673816681\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.8236 - accuracy: 0.3434\n",
      "Density: 800\n",
      "Final Training Loss: 1.1537593603134155\n",
      "Final Training Accuracy: 0.7814546823501587\n",
      "Final Validation Loss: 6.720355987548828\n",
      "Final Validation Accuracy: 0.3480358421802521\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.6743 - accuracy: 0.3611\n",
      "Density: 850\n",
      "Final Training Loss: 1.2658151388168335\n",
      "Final Training Accuracy: 0.7747328281402588\n",
      "Final Validation Loss: 6.405538082122803\n",
      "Final Validation Accuracy: 0.362508624792099\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.3187 - accuracy: 0.3462\n",
      "Density: 900\n",
      "Final Training Loss: 1.184953212738037\n",
      "Final Training Accuracy: 0.7795587778091431\n",
      "Final Validation Loss: 6.843349456787109\n",
      "Final Validation Accuracy: 0.3652653396129608\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.4831 - accuracy: 0.3313\n",
      "Density: 950\n",
      "Final Training Loss: 1.2957971096038818\n",
      "Final Training Accuracy: 0.7733539938926697\n",
      "Final Validation Loss: 7.306069374084473\n",
      "Final Validation Accuracy: 0.362508624792099\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.6246 - accuracy: 0.3550\n",
      "Density: 1000\n",
      "Final Training Loss: 1.3540605306625366\n",
      "Final Training Accuracy: 0.7733539938926697\n",
      "Final Validation Loss: 7.348328113555908\n",
      "Final Validation Accuracy: 0.36457616090774536\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.8943 - accuracy: 0.3429\n",
      "Density: 1050\n",
      "Final Training Loss: 1.1400238275527954\n",
      "Final Training Accuracy: 0.7928300499916077\n",
      "Final Validation Loss: 7.47238302230835\n",
      "Final Validation Accuracy: 0.36457616090774536\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 7.9614 - accuracy: 0.3407\n",
      "Density: 1100\n",
      "Final Training Loss: 1.324101209640503\n",
      "Final Training Accuracy: 0.7780075669288635\n",
      "Final Validation Loss: 8.06065559387207\n",
      "Final Validation Accuracy: 0.3432115912437439\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.0907 - accuracy: 0.3412\n",
      "Density: 1150\n",
      "Final Training Loss: 1.0791186094284058\n",
      "Final Training Accuracy: 0.8117890357971191\n",
      "Final Validation Loss: 7.827176570892334\n",
      "Final Validation Accuracy: 0.37077876925468445\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.0690 - accuracy: 0.3583\n",
      "Density: 1200\n",
      "Final Training Loss: 0.9552628397941589\n",
      "Final Training Accuracy: 0.8326439261436462\n",
      "Final Validation Loss: 7.807467937469482\n",
      "Final Validation Accuracy: 0.36044108867645264\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.3704 - accuracy: 0.3550\n",
      "Density: 1250\n",
      "Final Training Loss: 1.0827082395553589\n",
      "Final Training Accuracy: 0.8198896646499634\n",
      "Final Validation Loss: 8.234389305114746\n",
      "Final Validation Accuracy: 0.35768434405326843\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.6462 - accuracy: 0.3479\n",
      "Density: 1300\n",
      "Final Training Loss: 0.9302762746810913\n",
      "Final Training Accuracy: 0.8374698162078857\n",
      "Final Validation Loss: 8.488085746765137\n",
      "Final Validation Accuracy: 0.36802205443382263\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.0062 - accuracy: 0.3462\n",
      "Density: 1350\n",
      "Final Training Loss: 1.0915441513061523\n",
      "Final Training Accuracy: 0.8243709206581116\n",
      "Final Validation Loss: 8.910614967346191\n",
      "Final Validation Accuracy: 0.370089590549469\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 8.9850 - accuracy: 0.3512\n",
      "Density: 1400\n",
      "Final Training Loss: 1.0565345287322998\n",
      "Final Training Accuracy: 0.8297138810157776\n",
      "Final Validation Loss: 8.548378944396973\n",
      "Final Validation Accuracy: 0.38111647963523865\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.3811 - accuracy: 0.3594\n",
      "Density: 1450\n",
      "Final Training Loss: 0.9203879237174988\n",
      "Final Training Accuracy: 0.8438469767570496\n",
      "Final Validation Loss: 9.156889915466309\n",
      "Final Validation Accuracy: 0.3742246627807617\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.0384 - accuracy: 0.3512\n",
      "Density: 1500\n",
      "Final Training Loss: 1.0979279279708862\n",
      "Final Training Accuracy: 0.8307480216026306\n",
      "Final Validation Loss: 9.17653751373291\n",
      "Final Validation Accuracy: 0.38525155186653137\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9.5279 - accuracy: 0.3434\n",
      "Density: 1550\n",
      "Final Training Loss: 1.0126276016235352\n",
      "Final Training Accuracy: 0.8450534343719482\n",
      "Final Validation Loss: 9.619216918945312\n",
      "Final Validation Accuracy: 0.34872502088546753\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.2224 - accuracy: 0.3545\n",
      "Density: 1600\n",
      "Final Training Loss: 1.030758261680603\n",
      "Final Training Accuracy: 0.8362633585929871\n",
      "Final Validation Loss: 9.791729927062988\n",
      "Final Validation Accuracy: 0.36319780349731445\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.3711 - accuracy: 0.3545\n",
      "Density: 1650\n",
      "Final Training Loss: 0.9817721843719482\n",
      "Final Training Accuracy: 0.8457428216934204\n",
      "Final Validation Loss: 10.174097061157227\n",
      "Final Validation Accuracy: 0.3638869822025299\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.2074 - accuracy: 0.3693\n",
      "Density: 1700\n",
      "Final Training Loss: 1.0013835430145264\n",
      "Final Training Accuracy: 0.849362313747406\n",
      "Final Validation Loss: 10.424910545349121\n",
      "Final Validation Accuracy: 0.3818056583404541\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.0908 - accuracy: 0.3456\n",
      "Density: 1750\n",
      "Final Training Loss: 1.026480793952942\n",
      "Final Training Accuracy: 0.8491899371147156\n",
      "Final Validation Loss: 10.219727516174316\n",
      "Final Validation Accuracy: 0.3756030201911926\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.7068 - accuracy: 0.3534\n",
      "Density: 1800\n",
      "Final Training Loss: 1.1099931001663208\n",
      "Final Training Accuracy: 0.8331609964370728\n",
      "Final Validation Loss: 10.571883201599121\n",
      "Final Validation Accuracy: 0.3638869822025299\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.6747 - accuracy: 0.3705\n",
      "Density: 1850\n",
      "Final Training Loss: 0.9337490797042847\n",
      "Final Training Accuracy: 0.8598759174346924\n",
      "Final Validation Loss: 10.552800178527832\n",
      "Final Validation Accuracy: 0.3687112331390381\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.3832 - accuracy: 0.3423\n",
      "Density: 1900\n",
      "Final Training Loss: 1.0535625219345093\n",
      "Final Training Accuracy: 0.849362313747406\n",
      "Final Validation Loss: 11.223767280578613\n",
      "Final Validation Accuracy: 0.3535492718219757\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.1889 - accuracy: 0.3473\n",
      "Density: 1950\n",
      "Final Training Loss: 1.0134996175765991\n",
      "Final Training Accuracy: 0.8514305353164673\n",
      "Final Validation Loss: 11.099090576171875\n",
      "Final Validation Accuracy: 0.3742246627807617\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12.0636 - accuracy: 0.3512\n",
      "Density: 2000\n",
      "Final Training Loss: 1.1025038957595825\n",
      "Final Training Accuracy: 0.8503963947296143\n",
      "Final Validation Loss: 11.499139785766602\n",
      "Final Validation Accuracy: 0.3673328757286072\n"
     ]
    }
   ],
   "source": [
    "# Tests with the plain pca data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "# Density 50 to 2000\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(50, 2001, 50):\n",
    "        title_appendix = f'd{i}'\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(i, activation='relu'))\n",
    "        model.add(Dense(19, activation='softmax'))\n",
    "    \n",
    "        # Compile the model\n",
    "        optimizer=RMSprop(learning_rate=0.001)\n",
    "        if opti == 'ADAM':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        # Fit the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "    \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('Density: %.i' % (i))\n",
    "        print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "        print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "        print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "        print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "        visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "\n",
    "        # Clear Keras session\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdfa5cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8674 - accuracy: 0.7630\n",
      "Density: 50\n",
      "Final Training Loss: 0.00015400766278617084\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.8316102027893066\n",
      "Final Validation Accuracy: 0.7849758863449097\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8124 - accuracy: 0.7817\n",
      "Density: 100\n",
      "Final Training Loss: 0.00011275355063844472\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7538713216781616\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7961 - accuracy: 0.7883\n",
      "Density: 150\n",
      "Final Training Loss: 9.916954149957746e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7595594525337219\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7899 - accuracy: 0.7922\n",
      "Density: 200\n",
      "Final Training Loss: 0.00011909726163139567\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7342316508293152\n",
      "Final Validation Accuracy: 0.7960027456283569\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7920 - accuracy: 0.7911\n",
      "Density: 250\n",
      "Final Training Loss: 0.0001103622853406705\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7390182018280029\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.7949\n",
      "Density: 300\n",
      "Final Training Loss: 0.00010710610513342544\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7431588172912598\n",
      "Final Validation Accuracy: 0.793935239315033\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.7966\n",
      "Density: 350\n",
      "Final Training Loss: 9.939837036654353e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7359908819198608\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8069 - accuracy: 0.7878\n",
      "Density: 400\n",
      "Final Training Loss: 9.691038576420397e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.716773509979248\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7903 - accuracy: 0.7988\n",
      "Density: 450\n",
      "Final Training Loss: 9.28919980651699e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7175824046134949\n",
      "Final Validation Accuracy: 0.807029664516449\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7751 - accuracy: 0.7933\n",
      "Density: 500\n",
      "Final Training Loss: 8.884812268661335e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.706913411617279\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.8087\n",
      "Density: 550\n",
      "Final Training Loss: 8.753410656936467e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7453112006187439\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7883 - accuracy: 0.8004\n",
      "Density: 600\n",
      "Final Training Loss: 8.400168735533953e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7154772281646729\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8092 - accuracy: 0.7949\n",
      "Density: 650\n",
      "Final Training Loss: 9.218967898050323e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7409555912017822\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8117 - accuracy: 0.7922\n",
      "Density: 700\n",
      "Final Training Loss: 7.855909643694758e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7378340363502502\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7914 - accuracy: 0.7949\n",
      "Density: 750\n",
      "Final Training Loss: 7.54260690882802e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7049165368080139\n",
      "Final Validation Accuracy: 0.8104755282402039\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7951 - accuracy: 0.7977\n",
      "Density: 800\n",
      "Final Training Loss: 7.505633402615786e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7473776936531067\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8178 - accuracy: 0.7938\n",
      "Density: 850\n",
      "Final Training Loss: 7.544994150521234e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7406905889511108\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7933 - accuracy: 0.7999\n",
      "Density: 900\n",
      "Final Training Loss: 7.230683695524931e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7372419238090515\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8009 - accuracy: 0.8109\n",
      "Density: 950\n",
      "Final Training Loss: 7.066776015562937e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7243000268936157\n",
      "Final Validation Accuracy: 0.8132322430610657\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.8021\n",
      "Density: 1000\n",
      "Final Training Loss: 7.109367288649082e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7603256702423096\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.8087\n",
      "Density: 1050\n",
      "Final Training Loss: 6.880831642774865e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.741422176361084\n",
      "Final Validation Accuracy: 0.8063404560089111\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7923 - accuracy: 0.8021\n",
      "Density: 1100\n",
      "Final Training Loss: 7.296477269846946e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7356842756271362\n",
      "Final Validation Accuracy: 0.807718813419342\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8239 - accuracy: 0.7966\n",
      "Density: 1150\n",
      "Final Training Loss: 6.703578401356936e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7364602088928223\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8391 - accuracy: 0.7916\n",
      "Density: 1200\n",
      "Final Training Loss: 6.383955769706517e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7440099716186523\n",
      "Final Validation Accuracy: 0.8063404560089111\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8315 - accuracy: 0.7982\n",
      "Density: 1250\n",
      "Final Training Loss: 6.472168024629354e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7487114667892456\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8189 - accuracy: 0.7966\n",
      "Density: 1300\n",
      "Final Training Loss: 6.426743493648246e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7694527506828308\n",
      "Final Validation Accuracy: 0.807718813419342\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8491 - accuracy: 0.7999\n",
      "Density: 1350\n",
      "Final Training Loss: 6.187160761328414e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7454912066459656\n",
      "Final Validation Accuracy: 0.8104755282402039\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8231 - accuracy: 0.7971\n",
      "Density: 1400\n",
      "Final Training Loss: 6.145544466562569e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7893508672714233\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8208 - accuracy: 0.7977\n",
      "Density: 1450\n",
      "Final Training Loss: 5.886903454666026e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7423037886619568\n",
      "Final Validation Accuracy: 0.807718813419342\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8535 - accuracy: 0.7988\n",
      "Density: 1500\n",
      "Final Training Loss: 6.196221511345357e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7592810392379761\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8467 - accuracy: 0.8076\n",
      "Density: 1550\n",
      "Final Training Loss: 7.422096678055823e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.8194617033004761\n",
      "Final Validation Accuracy: 0.7987594604492188\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8208 - accuracy: 0.7933\n",
      "Density: 1600\n",
      "Final Training Loss: 5.807924026157707e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7548075914382935\n",
      "Final Validation Accuracy: 0.7953135967254639\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8292 - accuracy: 0.7955\n",
      "Density: 1650\n",
      "Final Training Loss: 5.691077240044251e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7748937010765076\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8310 - accuracy: 0.7944\n",
      "Density: 1700\n",
      "Final Training Loss: 5.6484699598513544e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7718890905380249\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8848 - accuracy: 0.8026\n",
      "Density: 1750\n",
      "Final Training Loss: 5.5718744988553226e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.8011237978935242\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8033 - accuracy: 0.7993\n",
      "Density: 1800\n",
      "Final Training Loss: 5.546460670302622e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7717651724815369\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8679 - accuracy: 0.8010\n",
      "Density: 1850\n",
      "Final Training Loss: 5.7351873692823574e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7894370555877686\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8504 - accuracy: 0.8037\n",
      "Density: 1900\n",
      "Final Training Loss: 5.527834582608193e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7826318740844727\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8468 - accuracy: 0.7993\n",
      "Density: 1950\n",
      "Final Training Loss: 5.3594041673932225e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7700417637825012\n",
      "Final Validation Accuracy: 0.807718813419342\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8531 - accuracy: 0.8037\n",
      "Density: 2000\n",
      "Final Training Loss: 5.617629358312115e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.8265002965927124\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 9: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7756\n",
      "Density: 50\n",
      "Final Training Loss: 0.0013463852228596807\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.67458575963974\n",
      "Final Validation Accuracy: 0.7904893159866333\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.7878\n",
      "Density: 100\n",
      "Final Training Loss: 0.0012127961963415146\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6584161520004272\n",
      "Final Validation Accuracy: 0.7891109585762024\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.7878\n",
      "Density: 150\n",
      "Final Training Loss: 0.0013680339325219393\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6413166522979736\n",
      "Final Validation Accuracy: 0.7884217500686646\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.7971\n",
      "Density: 200\n",
      "Final Training Loss: 0.0011292408453300595\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6353884935379028\n",
      "Final Validation Accuracy: 0.792556881904602\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.7883\n",
      "Density: 250\n",
      "Final Training Loss: 0.0006565797375515103\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6264209151268005\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.7938\n",
      "Density: 300\n",
      "Final Training Loss: 0.0005874101188965142\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6475424766540527\n",
      "Final Validation Accuracy: 0.7911785244941711\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.7971\n",
      "Density: 350\n",
      "Final Training Loss: 0.0005426618736237288\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6284008622169495\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.7944\n",
      "Density: 400\n",
      "Final Training Loss: 0.0007268437184393406\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6322503685951233\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.7949\n",
      "Density: 450\n",
      "Final Training Loss: 0.000681703444570303\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6194210052490234\n",
      "Final Validation Accuracy: 0.7960027456283569\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.7955\n",
      "Density: 500\n",
      "Final Training Loss: 0.0004358437145128846\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6173902153968811\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.7960\n",
      "Density: 550\n",
      "Final Training Loss: 0.0005916624795645475\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.609605610370636\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.7955\n",
      "Density: 600\n",
      "Final Training Loss: 0.0005727471434511244\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6140148043632507\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.8037\n",
      "Density: 650\n",
      "Final Training Loss: 0.0003659997310023755\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6281667947769165\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.8032\n",
      "Density: 700\n",
      "Final Training Loss: 0.0005148719646967947\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6044240593910217\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.8032\n",
      "Density: 750\n",
      "Final Training Loss: 0.000491976912599057\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.611841082572937\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.7993\n",
      "Density: 800\n",
      "Final Training Loss: 0.0004628972674254328\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.5961505174636841\n",
      "Final Validation Accuracy: 0.807718813419342\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.8026\n",
      "Density: 850\n",
      "Final Training Loss: 0.00044910007272846997\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6104758381843567\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.7977\n",
      "Density: 900\n",
      "Final Training Loss: 0.0004316985432524234\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6165515184402466\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.8043\n",
      "Density: 950\n",
      "Final Training Loss: 0.00041884827078320086\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6183387637138367\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.7949\n",
      "Density: 1000\n",
      "Final Training Loss: 0.0004127745924051851\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6383678913116455\n",
      "Final Validation Accuracy: 0.7987594604492188\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.8026\n",
      "Density: 1050\n",
      "Final Training Loss: 0.0003962265618611127\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6163076162338257\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.7999\n",
      "Density: 1100\n",
      "Final Training Loss: 0.0003890379739459604\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6264867782592773\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.7993\n",
      "Density: 1150\n",
      "Final Training Loss: 0.0003706673451233655\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6229175925254822\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.7955\n",
      "Density: 1200\n",
      "Final Training Loss: 0.00024534494150429964\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6321480870246887\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.8043\n",
      "Density: 1250\n",
      "Final Training Loss: 0.00035861824289895594\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6208021640777588\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.8010\n",
      "Density: 1300\n",
      "Final Training Loss: 0.00024028855841606855\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6097543835639954\n",
      "Final Validation Accuracy: 0.8084080219268799\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.7988\n",
      "Density: 1350\n",
      "Final Training Loss: 0.000341396895237267\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6244882345199585\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.7971\n",
      "Density: 1400\n",
      "Final Training Loss: 0.00033705582609400153\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6391080617904663\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.8049\n",
      "Density: 1450\n",
      "Final Training Loss: 0.00032756838481873274\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6113309860229492\n",
      "Final Validation Accuracy: 0.8063404560089111\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.8015\n",
      "Density: 1500\n",
      "Final Training Loss: 0.00022020898177288473\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.615031361579895\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.8010\n",
      "Density: 1550\n",
      "Final Training Loss: 0.0002192425454268232\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6269427537918091\n",
      "Final Validation Accuracy: 0.8042728900909424\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.8049\n",
      "Density: 1600\n",
      "Final Training Loss: 0.00021446842583827674\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6180293560028076\n",
      "Final Validation Accuracy: 0.8125430941581726\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.8060\n",
      "Density: 1650\n",
      "Final Training Loss: 0.00030440816772170365\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6454127430915833\n",
      "Final Validation Accuracy: 0.7953135967254639\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.8115\n",
      "Density: 1700\n",
      "Final Training Loss: 0.00029221930890344083\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6252660751342773\n",
      "Final Validation Accuracy: 0.8111647367477417\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.8054\n",
      "Density: 1750\n",
      "Final Training Loss: 0.0002871246251743287\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6356168985366821\n",
      "Final Validation Accuracy: 0.807718813419342\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.8037\n",
      "Density: 1800\n",
      "Final Training Loss: 0.00019936809258069843\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6283342838287354\n",
      "Final Validation Accuracy: 0.8084080219268799\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.8004\n",
      "Density: 1850\n",
      "Final Training Loss: 0.00019740668358281255\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6425020098686218\n",
      "Final Validation Accuracy: 0.809097170829773\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.7988\n",
      "Density: 1900\n",
      "Final Training Loss: 0.000278577848803252\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6294874548912048\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7944\n",
      "Density: 1950\n",
      "Final Training Loss: 0.0002641752071212977\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6372242569923401\n",
      "Final Validation Accuracy: 0.8049620985984802\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.8021\n",
      "Density: 2000\n",
      "Final Training Loss: 0.00018393274513073266\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6569420695304871\n",
      "Final Validation Accuracy: 0.7994486689567566\n"
     ]
    }
   ],
   "source": [
    "# Tests with fourie transformation only\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fourie_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "# Density 50 to 2000\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(50, 2001, 50):\n",
    "        title_appendix = f'd{i}'\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(i, activation='relu'))\n",
    "        model.add(Dense(19, activation='softmax'))\n",
    "    \n",
    "        # Compile the model\n",
    "        optimizer=RMSprop(learning_rate=0.001)\n",
    "        if opti == 'ADAM':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        # Fit the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "    \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('Density: %.i' % (i))\n",
    "        print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "        print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "        print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "        print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "        visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "\n",
    "        # Clear Keras session\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e6f396-6bda-40c6-80e1-9e09ca073784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.7806\n",
      "Density: 50\n",
      "Final Training Loss: 0.0002594952820800245\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7704319357872009\n",
      "Final Validation Accuracy: 0.7856650352478027\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8209 - accuracy: 0.7889\n",
      "Density: 100\n",
      "Final Training Loss: 0.00023736979346722364\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7373093366622925\n",
      "Final Validation Accuracy: 0.7904893159866333\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8153 - accuracy: 0.7889\n",
      "Density: 150\n",
      "Final Training Loss: 0.00020279006275814027\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7196061611175537\n",
      "Final Validation Accuracy: 0.7898001670837402\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.7905\n",
      "Density: 200\n",
      "Final Training Loss: 0.0001799541641958058\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7214510440826416\n",
      "Final Validation Accuracy: 0.7904893159866333\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8214 - accuracy: 0.7905\n",
      "Density: 250\n",
      "Final Training Loss: 0.000171349267475307\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7207053899765015\n",
      "Final Validation Accuracy: 0.7953135967254639\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8232 - accuracy: 0.7905\n",
      "Density: 300\n",
      "Final Training Loss: 0.0001653582148719579\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7128153443336487\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8250 - accuracy: 0.7900\n",
      "Density: 350\n",
      "Final Training Loss: 0.00015666583203710616\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7033710479736328\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.7944\n",
      "Density: 400\n",
      "Final Training Loss: 0.00015005124441813678\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6960837244987488\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8058 - accuracy: 0.7872\n",
      "Density: 450\n",
      "Final Training Loss: 0.00014539928815793246\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7096852660179138\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8321 - accuracy: 0.7927\n",
      "Density: 500\n",
      "Final Training Loss: 0.00014246605860535055\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7182484269142151\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7953 - accuracy: 0.7944\n",
      "Density: 550\n",
      "Final Training Loss: 0.00017754259170033038\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.698354184627533\n",
      "Final Validation Accuracy: 0.794624388217926\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8161 - accuracy: 0.7993\n",
      "Density: 600\n",
      "Final Training Loss: 0.00017272606783080846\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.709070086479187\n",
      "Final Validation Accuracy: 0.807029664516449\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7907 - accuracy: 0.7999\n",
      "Density: 650\n",
      "Final Training Loss: 0.00016936085012275726\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6993860602378845\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.7988\n",
      "Density: 700\n",
      "Final Training Loss: 0.00016425299691036344\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6938225030899048\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.7960\n",
      "Density: 750\n",
      "Final Training Loss: 0.00016278027032967657\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.713039219379425\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7847 - accuracy: 0.8021\n",
      "Density: 800\n",
      "Final Training Loss: 0.00015852894284762442\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6952479481697083\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7874 - accuracy: 0.8021\n",
      "Density: 850\n",
      "Final Training Loss: 0.00015574504504911602\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7158840894699097\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7895 - accuracy: 0.7960\n",
      "Density: 900\n",
      "Final Training Loss: 0.00015504700422752649\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7082366347312927\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8116 - accuracy: 0.8026\n",
      "Density: 950\n",
      "Final Training Loss: 0.0001562580291647464\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7187661528587341\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.8043\n",
      "Density: 1000\n",
      "Final Training Loss: 0.00014877509966026992\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6988997459411621\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7963 - accuracy: 0.7999\n",
      "Density: 1050\n",
      "Final Training Loss: 0.00014817774354014546\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6986961364746094\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8119 - accuracy: 0.7966\n",
      "Density: 1100\n",
      "Final Training Loss: 0.00014906254364177585\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7104808688163757\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8156 - accuracy: 0.8032\n",
      "Density: 1150\n",
      "Final Training Loss: 0.0001455738238291815\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7247809767723083\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8160 - accuracy: 0.7955\n",
      "Density: 1200\n",
      "Final Training Loss: 0.0001405758666805923\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6819560527801514\n",
      "Final Validation Accuracy: 0.8097863793373108\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8020 - accuracy: 0.7949\n",
      "Density: 1250\n",
      "Final Training Loss: 0.00014399854990188032\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7074708342552185\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7943 - accuracy: 0.8037\n",
      "Density: 1300\n",
      "Final Training Loss: 0.0001428305549779907\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7054464221000671\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.8004\n",
      "Density: 1350\n",
      "Final Training Loss: 0.00013630688772536814\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7010002732276917\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.8071\n",
      "Density: 1400\n",
      "Final Training Loss: 0.00013659730029758066\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6952884793281555\n",
      "Final Validation Accuracy: 0.8111647367477417\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8141 - accuracy: 0.7977\n",
      "Density: 1450\n",
      "Final Training Loss: 0.00013694886001758277\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7031111717224121\n",
      "Final Validation Accuracy: 0.809097170829773\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7921 - accuracy: 0.8010\n",
      "Density: 1500\n",
      "Final Training Loss: 0.00012984548811800778\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6942664980888367\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.8021\n",
      "Density: 1550\n",
      "Final Training Loss: 0.00013282762665767223\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7275434136390686\n",
      "Final Validation Accuracy: 0.8042728900909424\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8230 - accuracy: 0.8021\n",
      "Density: 1600\n",
      "Final Training Loss: 0.0001289069768972695\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7177789211273193\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.7971\n",
      "Density: 1650\n",
      "Final Training Loss: 0.00012667528062593192\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7198476195335388\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7867 - accuracy: 0.7949\n",
      "Density: 1700\n",
      "Final Training Loss: 0.0001247373002115637\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7135508060455322\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8171 - accuracy: 0.8032\n",
      "Density: 1750\n",
      "Final Training Loss: 0.00012490811059251428\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.709010899066925\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8468 - accuracy: 0.7922\n",
      "Density: 1800\n",
      "Final Training Loss: 0.00012298475485295057\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7118824124336243\n",
      "Final Validation Accuracy: 0.8097863793373108\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8276 - accuracy: 0.7993\n",
      "Density: 1850\n",
      "Final Training Loss: 0.00012581881310325116\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7227689027786255\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.7993\n",
      "Density: 1900\n",
      "Final Training Loss: 0.00012216594768688083\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7216573357582092\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.8026\n",
      "Density: 1950\n",
      "Final Training Loss: 0.00012293994950596243\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7006444931030273\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8387 - accuracy: 0.8010\n",
      "Density: 2000\n",
      "Final Training Loss: 0.00012281601084396243\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7260425090789795\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "Epoch 9: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7677 - accuracy: 0.7745\n",
      "Density: 50\n",
      "Final Training Loss: 0.002142199082300067\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6784138083457947\n",
      "Final Validation Accuracy: 0.7753273844718933\n",
      "Epoch 9: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.7778\n",
      "Density: 100\n",
      "Final Training Loss: 0.0011739112669602036\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6540526747703552\n",
      "Final Validation Accuracy: 0.7863542437553406\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.7839\n",
      "Density: 150\n",
      "Final Training Loss: 0.001274611335247755\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6464510560035706\n",
      "Final Validation Accuracy: 0.7884217500686646\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.7778\n",
      "Density: 200\n",
      "Final Training Loss: 0.0010214290814474225\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6490346193313599\n",
      "Final Validation Accuracy: 0.7835975289344788\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.7900\n",
      "Density: 250\n",
      "Final Training Loss: 0.0008891810430213809\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6359320282936096\n",
      "Final Validation Accuracy: 0.7829083204269409\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.7889\n",
      "Density: 300\n",
      "Final Training Loss: 0.0011647704523056746\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6347019672393799\n",
      "Final Validation Accuracy: 0.7891109585762024\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.7850\n",
      "Density: 350\n",
      "Final Training Loss: 0.0007337062852457166\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6379554271697998\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.7811\n",
      "Density: 400\n",
      "Final Training Loss: 0.0006599250482395291\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6352519989013672\n",
      "Final Validation Accuracy: 0.7856650352478027\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.7845\n",
      "Density: 450\n",
      "Final Training Loss: 0.0009244346292689443\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6244725584983826\n",
      "Final Validation Accuracy: 0.792556881904602\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.7889\n",
      "Density: 500\n",
      "Final Training Loss: 0.0005751067074015737\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.630074679851532\n",
      "Final Validation Accuracy: 0.793935239315033\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.7916\n",
      "Density: 550\n",
      "Final Training Loss: 0.0005457937950268388\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6339111328125\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.7872\n",
      "Density: 600\n",
      "Final Training Loss: 0.0005137838888913393\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6223748922348022\n",
      "Final Validation Accuracy: 0.7960027456283569\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.8015\n",
      "Density: 650\n",
      "Final Training Loss: 0.0004902802756987512\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6338264346122742\n",
      "Final Validation Accuracy: 0.7911785244941711\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.7878\n",
      "Density: 700\n",
      "Final Training Loss: 0.0006838254630565643\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6236648559570312\n",
      "Final Validation Accuracy: 0.7953135967254639\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.7944\n",
      "Density: 750\n",
      "Final Training Loss: 0.0006653430173173547\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6152859926223755\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.7905\n",
      "Density: 800\n",
      "Final Training Loss: 0.000633962859865278\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6187340021133423\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7118 - accuracy: 0.7982\n",
      "Density: 850\n",
      "Final Training Loss: 0.00042080532875843346\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6274259090423584\n",
      "Final Validation Accuracy: 0.7994486689567566\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.7916\n",
      "Density: 900\n",
      "Final Training Loss: 0.0006042221793904901\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6201935410499573\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7905\n",
      "Density: 950\n",
      "Final Training Loss: 0.000560946180485189\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6146737337112427\n",
      "Final Validation Accuracy: 0.794624388217926\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.7966\n",
      "Density: 1000\n",
      "Final Training Loss: 0.0005505520384758711\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6193291544914246\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.7927\n",
      "Density: 1050\n",
      "Final Training Loss: 0.0005403117975220084\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6019042134284973\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.7960\n",
      "Density: 1100\n",
      "Final Training Loss: 0.0005224701017141342\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6098173260688782\n",
      "Final Validation Accuracy: 0.7953135967254639\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.7839\n",
      "Density: 1150\n",
      "Final Training Loss: 0.0005079408874735236\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6128832697868347\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.7966\n",
      "Density: 1200\n",
      "Final Training Loss: 0.0004900718340650201\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6044878363609314\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.7944\n",
      "Density: 1250\n",
      "Final Training Loss: 0.0004722253361251205\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6178004741668701\n",
      "Final Validation Accuracy: 0.8022053837776184\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.7911\n",
      "Density: 1300\n",
      "Final Training Loss: 0.00046807833132334054\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6160033345222473\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.7933\n",
      "Density: 1350\n",
      "Final Training Loss: 0.00045960358693264425\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6268782019615173\n",
      "Final Validation Accuracy: 0.792556881904602\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.8004\n",
      "Density: 1400\n",
      "Final Training Loss: 0.00043682445539161563\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6142860054969788\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.7861\n",
      "Density: 1450\n",
      "Final Training Loss: 0.0003016582049895078\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6306015849113464\n",
      "Final Validation Accuracy: 0.7953135967254639\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.7966\n",
      "Density: 1500\n",
      "Final Training Loss: 0.0004298798739910126\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6233503222465515\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.7916\n",
      "Density: 1550\n",
      "Final Training Loss: 0.0002897431841120124\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6167490482330322\n",
      "Final Validation Accuracy: 0.8001378178596497\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.7988\n",
      "Density: 1600\n",
      "Final Training Loss: 0.0004128792497795075\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.617605984210968\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.7933\n",
      "Density: 1650\n",
      "Final Training Loss: 0.0004034926532767713\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6002366542816162\n",
      "Final Validation Accuracy: 0.7973811030387878\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.7949\n",
      "Density: 1700\n",
      "Final Training Loss: 0.00039148807991296053\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6116143465042114\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.8015\n",
      "Density: 1750\n",
      "Final Training Loss: 0.0003890079096890986\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6155415177345276\n",
      "Final Validation Accuracy: 0.794624388217926\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.7966\n",
      "Density: 1800\n",
      "Final Training Loss: 0.0003774524957407266\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.630408763885498\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.7955\n",
      "Density: 1850\n",
      "Final Training Loss: 0.00037929569953121245\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6284370422363281\n",
      "Final Validation Accuracy: 0.7987594604492188\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.7933\n",
      "Density: 1900\n",
      "Final Training Loss: 0.00037227116990834475\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6166595816612244\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.8015\n",
      "Density: 1950\n",
      "Final Training Loss: 0.0003658500500023365\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6144186854362488\n",
      "Final Validation Accuracy: 0.794624388217926\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.7988\n",
      "Density: 2000\n",
      "Final Training Loss: 0.00035485834814608097\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6036709547042847\n",
      "Final Validation Accuracy: 0.7994486689567566\n"
     ]
    }
   ],
   "source": [
    "# Tests with butter bandpass and fourie transformation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fourie_bandpass_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "# Density 50 to 2000\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(50, 2001, 50):\n",
    "        title_appendix = f'd{i}'\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(i, activation='relu'))\n",
    "        model.add(Dense(19, activation='softmax'))\n",
    "    \n",
    "        # Compile the model\n",
    "        optimizer=RMSprop(learning_rate=0.001)\n",
    "        if opti == 'ADAM':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        # Fit the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "    \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('Density: %.i' % (i))\n",
    "        print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "        print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "        print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "        print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "        visualize_history(history, f'PCA_fourie_bandpass_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "        \n",
    "        # Clear Keras session\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1344f36-e9ab-4e80-9d9d-ba60bd703209",
   "metadata": {},
   "source": [
    "Während die mit der PCA transformierten Rohdaten mit einem einfachen Neuronalen Netz nur eine Genauigkeit von weniger als 40% erreicht, schaffen es die Neuronalen Netze welche mit den Daten lernen die aus vorverarbeiteten Daten durch die PCA erzugt werden auf um die 80%. Dies liegt mit Sicherheit auch daran, dass die Anzahl der Principal Components (und damit der Daten allgemein) mehr als doppelt so groß ist. \n",
    "\n",
    "Da die Model-Performance für die nur mit der Fourie-Transformation vorverarbeiteten Daten und die Daten welche zusätzlich noch gefiltert wurden nahezu identisch ist werden im Folgenden nur noch die Fourie-Transformierten Werte verwendet. Nun wird überprüft welchen Einfluss die Anzahl der Layer auf die Modelperformance hat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9245acf5-1e75-4628-a409-695d332c449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7879 - accuracy: 0.8065\n",
      "Layer: 1; Optimizer: RMSP\n",
      "Final Training Loss: 6.911968375789002e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7274727821350098\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5725 - accuracy: 0.7767\n",
      "Layer: 2; Optimizer: RMSP\n",
      "Final Training Loss: 7.593476038891822e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 1.4059661626815796\n",
      "Final Validation Accuracy: 0.7884217500686646\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.4062 - accuracy: 0.7304\n",
      "Layer: 3; Optimizer: RMSP\n",
      "Final Training Loss: 0.02097475156188011\n",
      "Final Training Accuracy: 0.9944846630096436\n",
      "Final Validation Loss: 2.212620496749878\n",
      "Final Validation Accuracy: 0.7574086785316467\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.3575 - accuracy: 0.7332\n",
      "Layer: 4; Optimizer: RMSP\n",
      "Final Training Loss: 0.034145329147577286\n",
      "Final Training Accuracy: 0.9922440648078918\n",
      "Final Validation Loss: 2.257394790649414\n",
      "Final Validation Accuracy: 0.7263956069946289\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.4950 - accuracy: 0.7365\n",
      "Layer: 5; Optimizer: RMSP\n",
      "Final Training Loss: 0.028129154816269875\n",
      "Final Training Accuracy: 0.994657039642334\n",
      "Final Validation Loss: 2.125021457672119\n",
      "Final Validation Accuracy: 0.7574086785316467\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.3852 - accuracy: 0.7288\n",
      "Layer: 6; Optimizer: RMSP\n",
      "Final Training Loss: 0.03315865993499756\n",
      "Final Training Accuracy: 0.9948293566703796\n",
      "Final Validation Loss: 2.0930840969085693\n",
      "Final Validation Accuracy: 0.7450034618377686\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.7993\n",
      "Layer: 1; Optimizer: ADAM\n",
      "Final Training Loss: 0.000398883392335847\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.609420120716095\n",
      "Final Validation Accuracy: 0.8042728900909424\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.7203 - accuracy: 0.7133\n",
      "Layer: 2; Optimizer: ADAM\n",
      "Final Training Loss: 0.10384421050548553\n",
      "Final Training Accuracy: 0.9724233150482178\n",
      "Final Validation Loss: 1.5484215021133423\n",
      "Final Validation Accuracy: 0.7195038199424744\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.4274 - accuracy: 0.7216\n",
      "Layer: 3; Optimizer: ADAM\n",
      "Final Training Loss: 0.11923401057720184\n",
      "Final Training Accuracy: 0.96811443567276\n",
      "Final Validation Loss: 1.3557794094085693\n",
      "Final Validation Accuracy: 0.7367332577705383\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5509 - accuracy: 0.6885\n",
      "Layer: 4; Optimizer: ADAM\n",
      "Final Training Loss: 0.09367583692073822\n",
      "Final Training Accuracy: 0.980523943901062\n",
      "Final Validation Loss: 1.4004554748535156\n",
      "Final Validation Accuracy: 0.6926257610321045\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.6290 - accuracy: 0.6891\n",
      "Layer: 5; Optimizer: ADAM\n",
      "Final Training Loss: 0.07331795245409012\n",
      "Final Training Accuracy: 0.9846604466438293\n",
      "Final Validation Loss: 1.479276180267334\n",
      "Final Validation Accuracy: 0.7077877521514893\n",
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4284 - accuracy: 0.7029\n",
      "Layer: 6; Optimizer: ADAM\n",
      "Final Training Loss: 0.08289545029401779\n",
      "Final Training Accuracy: 0.9822474718093872\n",
      "Final Validation Loss: 1.2935051918029785\n",
      "Final Validation Accuracy: 0.7257063984870911\n"
     ]
    }
   ],
   "source": [
    "# Tests with fourie transformation only\n",
    "# Add more Layer; starting with 1024 neurons; decrease the number of neurons in every following layer;\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fourie_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(6):\n",
    "        title_appendix = f'layer#{11-i}_optimizer={opti}'\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(pow(2,10), activation='relu'))\n",
    "        for x in range(i):\n",
    "            model.add(Dense(pow(2,10-(x+1)), activation='relu'))\n",
    "        model.add(Dense(19, activation='softmax'))\n",
    "        optimizer=RMSprop(learning_rate=0.001)\n",
    "        if opti == 'ADAM':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        # Fit the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "    \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('Layer: %.i; Optimizer: %s' % (i+1, opti))\n",
    "        print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "        print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "        print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "        print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "        visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "    \n",
    "        # Clear Keras session\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95615d69-50f6-4788-992a-06d5d7e7e8d9",
   "metadata": {},
   "source": [
    "Über alle verwendeten Methoden hinweg sieht man, dass das Early stopping sehr früh greift (nach 6 bzw. 7 Epochen) bedenkt man, dass die patience auf 5 gesetzt wurde heißt das, dass die Modelle bereits am Anfang ins Overfitting übergehen. Da dieses Verhalten unter anderem auf eine zu große Lernrate hinweisen kann wird im Folgenden mit geringeren Lernraten experimentiert.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d2ef58-edaf-4456-a0ae-ba9f1a5f772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7988\n",
      "Layer: 1; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00050\n",
      "Final Training Loss: 0.00019960582721978426\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6797791719436646\n",
      "Final Validation Accuracy: 0.8028945326805115\n",
      "Epoch 12: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.7938\n",
      "Layer: 1; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00010\n",
      "Final Training Loss: 0.001491366303525865\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6163101196289062\n",
      "Final Validation Accuracy: 0.8008270263671875\n",
      "Epoch 19: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7955\n",
      "Layer: 1; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00005\n",
      "Final Training Loss: 0.0024814556818455458\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.5922610759735107\n",
      "Final Validation Accuracy: 0.8056512475013733\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9726 - accuracy: 0.7839\n",
      "Layer: 2; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00050\n",
      "Final Training Loss: 3.6731409636558965e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.8646692633628845\n",
      "Final Validation Accuracy: 0.7870433926582336\n",
      "Epoch 9: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7336 - accuracy: 0.7839\n",
      "Layer: 2; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00010\n",
      "Final Training Loss: 0.0004352862888481468\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6985387206077576\n",
      "Final Validation Accuracy: 0.7884217500686646\n",
      "Epoch 11: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.7878\n",
      "Layer: 2; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00005\n",
      "Final Training Loss: 0.0013117820490151644\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.644436776638031\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3612 - accuracy: 0.7646\n",
      "Layer: 3; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00050\n",
      "Final Training Loss: 1.4725757864653133e-05\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 1.2614195346832275\n",
      "Final Validation Accuracy: 0.7787732481956482\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8079 - accuracy: 0.7789\n",
      "Layer: 3; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00010\n",
      "Final Training Loss: 0.00021239173656795174\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7519780397415161\n",
      "Final Validation Accuracy: 0.7891109585762024\n",
      "Epoch 10: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.7734\n",
      "Layer: 3; Optimizer: RMSP; (Starting-)Learning-Rate: 0.00005\n",
      "Final Training Loss: 0.0005954648368060589\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.7218142151832581\n",
      "Final Validation Accuracy: 0.7863542437553406\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.7905\n",
      "Layer: 1; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00050\n",
      "Final Training Loss: 0.0008235340937972069\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6261529922485352\n",
      "Final Validation Accuracy: 0.793935239315033\n",
      "Epoch 15: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7845\n",
      "Layer: 1; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00010\n",
      "Final Training Loss: 0.0011797830229625106\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6496885418891907\n",
      "Final Validation Accuracy: 0.7884217500686646\n",
      "Epoch 22: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7894\n",
      "Layer: 1; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00005\n",
      "Final Training Loss: 0.0007784396875649691\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6468056440353394\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "Epoch 8: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7382 - accuracy: 0.7999\n",
      "Layer: 2; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00050\n",
      "Final Training Loss: 0.0001168993185274303\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6707282066345215\n",
      "Final Validation Accuracy: 0.8015161752700806\n",
      "Epoch 10: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.7795\n",
      "Layer: 2; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00010\n",
      "Final Training Loss: 0.000994813977740705\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6576271653175354\n",
      "Final Validation Accuracy: 0.793935239315033\n",
      "Epoch 14: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.7773\n",
      "Layer: 2; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00005\n",
      "Final Training Loss: 0.0010630289325490594\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6687820553779602\n",
      "Final Validation Accuracy: 0.7773948907852173\n",
      "Epoch 6: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3423 - accuracy: 0.7172\n",
      "Layer: 3; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00050\n",
      "Final Training Loss: 0.0489613302052021\n",
      "Final Training Accuracy: 0.9858669638633728\n",
      "Final Validation Loss: 1.2112877368927002\n",
      "Final Validation Accuracy: 0.7215713262557983\n",
      "Epoch 9: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.7745\n",
      "Layer: 3; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00010\n",
      "Final Training Loss: 0.000722751603461802\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6981151700019836\n",
      "Final Validation Accuracy: 0.7801516056060791\n",
      "Epoch 11: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7450 - accuracy: 0.7668\n",
      "Layer: 3; Optimizer: ADAM; (Starting-)Learning-Rate: 0.00005\n",
      "Final Training Loss: 0.0014427067944779992\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6811632513999939\n",
      "Final Validation Accuracy: 0.7711922526359558\n"
     ]
    }
   ],
   "source": [
    "# Tests with fourie transformation only\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fourie_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(3):\n",
    "        for lr in [0.0005,0.0001,0.00005]:\n",
    "            title_appendix = f'layer{11-i}_optimizer={opti}_lr={lr}'\n",
    "            # Build the model\n",
    "            model = Sequential()\n",
    "            model.add(Dense(pow(2,10), activation='relu'))\n",
    "            for x in range(i):\n",
    "                model.add(Dense(pow(2,10-(x+1)), activation='relu'))\n",
    "            model.add(Dense(19, activation='softmax'))\n",
    "            optimizer=RMSprop(learning_rate=lr)\n",
    "            if opti == 'ADAM':\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "        \n",
    "            # Fit the model\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "            history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "        \n",
    "            # Evaluate the model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "            print('Layer: %.i; Optimizer: %s; (Starting-)Learning-Rate: %.5f' % (i+1, opti, lr))\n",
    "            print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "            print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "            print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "            print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "            visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "        \n",
    "            # Clear Keras session\n",
    "            K.clear_session()\n",
    "            del model\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e389d9a-8040-47f4-aed9-aa775fee7d33",
   "metadata": {},
   "source": [
    "Da der loss immer noch sehr schnell nach oben geht wird nun zusätzlich noch Dropoutregularisierung eingebaut. Es wird im folgenden die niedrigste gestestete Lernrate für beide Optimierer verwendet (0.00005)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbdac572-c40d-4225-b8e1-4d4c5fd13a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.7911\n",
      "Layer: 1; Optimizer: RMSP; Dropout-Rate: 0.20\n",
      "Final Training Loss: 0.002768370322883129\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6174325346946716\n",
      "Final Validation Accuracy: 0.7966919541358948\n",
      "Epoch 20: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7933\n",
      "Layer: 1; Optimizer: RMSP; Dropout-Rate: 0.35\n",
      "Final Training Loss: 0.004757148679345846\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6148341298103333\n",
      "Final Validation Accuracy: 0.7904893159866333\n",
      "Epoch 22: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.7933\n",
      "Layer: 1; Optimizer: RMSP; Dropout-Rate: 0.50\n",
      "Final Training Loss: 0.00601459015160799\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6206346750259399\n",
      "Final Validation Accuracy: 0.793935239315033\n",
      "Epoch 13: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.7839\n",
      "Layer: 2; Optimizer: RMSP; Dropout-Rate: 0.20\n",
      "Final Training Loss: 0.0024216226302087307\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6742698550224304\n",
      "Final Validation Accuracy: 0.7911785244941711\n",
      "Epoch 14: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.7839\n",
      "Layer: 2; Optimizer: RMSP; Dropout-Rate: 0.35\n",
      "Final Training Loss: 0.005910017527639866\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6720882058143616\n",
      "Final Validation Accuracy: 0.7877326011657715\n",
      "Epoch 18: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7555 - accuracy: 0.7756\n",
      "Layer: 2; Optimizer: RMSP; Dropout-Rate: 0.50\n",
      "Final Training Loss: 0.011353280395269394\n",
      "Final Training Accuracy: 0.9994829297065735\n",
      "Final Validation Loss: 0.6762515902519226\n",
      "Final Validation Accuracy: 0.7898001670837402\n",
      "Epoch 12: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8144 - accuracy: 0.7762\n",
      "Layer: 3; Optimizer: RMSP; Dropout-Rate: 0.20\n",
      "Final Training Loss: 0.004325913265347481\n",
      "Final Training Accuracy: 0.9994829297065735\n",
      "Final Validation Loss: 0.7553638815879822\n",
      "Final Validation Accuracy: 0.7856650352478027\n",
      "Epoch 15: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8569 - accuracy: 0.7707\n",
      "Layer: 3; Optimizer: RMSP; Dropout-Rate: 0.35\n",
      "Final Training Loss: 0.0184420645236969\n",
      "Final Training Accuracy: 0.9965528845787048\n",
      "Final Validation Loss: 0.8290416598320007\n",
      "Final Validation Accuracy: 0.7691247463226318\n",
      "Epoch 19: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8466 - accuracy: 0.7652\n",
      "Layer: 3; Optimizer: RMSP; Dropout-Rate: 0.50\n",
      "Final Training Loss: 0.099180668592453\n",
      "Final Training Accuracy: 0.9701827168464661\n",
      "Final Validation Loss: 0.8030892014503479\n",
      "Final Validation Accuracy: 0.7677463889122009\n",
      "Epoch 23: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.7767\n",
      "Layer: 1; Optimizer: ADAM; Dropout-Rate: 0.20\n",
      "Final Training Loss: 0.0009978263406082988\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6468359231948853\n",
      "Final Validation Accuracy: 0.7856650352478027\n",
      "Epoch 24: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7850\n",
      "Layer: 1; Optimizer: ADAM; Dropout-Rate: 0.35\n",
      "Final Training Loss: 0.0013218163512647152\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6349157691001892\n",
      "Final Validation Accuracy: 0.7884217500686646\n",
      "Epoch 25: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.7839\n",
      "Layer: 1; Optimizer: ADAM; Dropout-Rate: 0.50\n",
      "Final Training Loss: 0.002378322184085846\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6317616701126099\n",
      "Final Validation Accuracy: 0.7918676733970642\n",
      "Epoch 15: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.7806\n",
      "Layer: 2; Optimizer: ADAM; Dropout-Rate: 0.20\n",
      "Final Training Loss: 0.0022373495157808065\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6724382638931274\n",
      "Final Validation Accuracy: 0.7870433926582336\n",
      "Epoch 17: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7263 - accuracy: 0.7718\n",
      "Layer: 2; Optimizer: ADAM; Dropout-Rate: 0.35\n",
      "Final Training Loss: 0.0046806433238089085\n",
      "Final Training Accuracy: 0.9998276233673096\n",
      "Final Validation Loss: 0.6990812420845032\n",
      "Final Validation Accuracy: 0.7856650352478027\n",
      "Epoch 17: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.7778\n",
      "Layer: 2; Optimizer: ADAM; Dropout-Rate: 0.50\n",
      "Final Training Loss: 0.022228868678212166\n",
      "Final Training Accuracy: 0.9972423315048218\n",
      "Final Validation Loss: 0.6609745025634766\n",
      "Final Validation Accuracy: 0.7849758863449097\n",
      "Epoch 12: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8151 - accuracy: 0.7635\n",
      "Layer: 3; Optimizer: ADAM; Dropout-Rate: 0.20\n",
      "Final Training Loss: 0.008001748472452164\n",
      "Final Training Accuracy: 0.9996553063392639\n",
      "Final Validation Loss: 0.74896639585495\n",
      "Final Validation Accuracy: 0.7732598185539246\n",
      "Epoch 13: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7820 - accuracy: 0.7707\n",
      "Layer: 3; Optimizer: ADAM; Dropout-Rate: 0.35\n",
      "Final Training Loss: 0.03203647583723068\n",
      "Final Training Accuracy: 0.9963805675506592\n",
      "Final Validation Loss: 0.7097423076629639\n",
      "Final Validation Accuracy: 0.7649896740913391\n",
      "Epoch 20: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8169 - accuracy: 0.7756\n",
      "Layer: 3; Optimizer: ADAM; Dropout-Rate: 0.50\n",
      "Final Training Loss: 0.048635467886924744\n",
      "Final Training Accuracy: 0.9898310899734497\n",
      "Final Validation Loss: 0.7504236698150635\n",
      "Final Validation Accuracy: 0.779462456703186\n"
     ]
    }
   ],
   "source": [
    "# Tests with fourie transformation only\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fourie_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(3):\n",
    "        for dor in [0.2, 0.35, 0.5]:\n",
    "            title_appendix = f'layer{11-i}_optimizer={opti}_dropout={dor}'\n",
    "            # Build the model\n",
    "            model = Sequential()\n",
    "            model.add(Dense(pow(2,10), activation='relu'))\n",
    "            model.add(Dropout(dor))\n",
    "            for x in range(i):\n",
    "                model.add(Dense(pow(2,10-(x+1)), activation='relu'))\n",
    "                model.add(Dropout(dor))\n",
    "            model.add(Dense(19, activation='softmax'))\n",
    "            optimizer=RMSprop(learning_rate=0.00005)\n",
    "            if opti == 'ADAM':\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "        \n",
    "            # Fit the model\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "            history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "        \n",
    "            # Evaluate the model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "            print('Layer: %.i; Optimizer: %s; Dropout-Rate: %.2f' % (i+1, opti, dor))\n",
    "            print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "            print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "            print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "            print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "            visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "        \n",
    "            # Clear Keras session\n",
    "            K.clear_session()\n",
    "            del model\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac12de-0cc8-48a0-b91d-fac45d508ae5",
   "metadata": {},
   "source": [
    "Mit der reduzierten Lernrate und den zusätzlichen Dropout-Layern lässt sich zwar das Overfitting effektiv verhindern, die Modellperformance zeigt leider keine Verbesserung. Als letzter Versuch werden noch verschiedene batchsizes ausprobiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0e4b5a7-f29c-47ac-8c6e-9e997f270846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.7955\n",
      "Layer: 1; Optimizer: RMSP; Batchsize: 25\n",
      "Final Training Loss: 0.007414570078253746\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6041816473007202\n",
      "Final Validation Accuracy: 0.7980703115463257\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7971\n",
      "Layer: 1; Optimizer: RMSP; Batchsize: 50\n",
      "Final Training Loss: 0.011497807689011097\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.5832279920578003\n",
      "Final Validation Accuracy: 0.8035837411880493\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.7856\n",
      "Layer: 1; Optimizer: RMSP; Batchsize: 100\n",
      "Final Training Loss: 0.052916787564754486\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6140007376670837\n",
      "Final Validation Accuracy: 0.7911785244941711\n",
      "Epoch 22: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.7916\n",
      "Layer: 2; Optimizer: RMSP; Batchsize: 25\n",
      "Final Training Loss: 0.011675678193569183\n",
      "Final Training Accuracy: 0.9993105530738831\n",
      "Final Validation Loss: 0.6560309529304504\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 30: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.7883\n",
      "Layer: 2; Optimizer: RMSP; Batchsize: 50\n",
      "Final Training Loss: 0.01649530418217182\n",
      "Final Training Accuracy: 0.9994829297065735\n",
      "Final Validation Loss: 0.6389466524124146\n",
      "Final Validation Accuracy: 0.7918676733970642\n",
      "Epoch 46: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.7922\n",
      "Layer: 2; Optimizer: RMSP; Batchsize: 100\n",
      "Final Training Loss: 0.018733080476522446\n",
      "Final Training Accuracy: 0.998965859413147\n",
      "Final Validation Loss: 0.6131483912467957\n",
      "Final Validation Accuracy: 0.7932460308074951\n",
      "Epoch 18: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.7729\n",
      "Layer: 3; Optimizer: RMSP; Batchsize: 25\n",
      "Final Training Loss: 0.04568643495440483\n",
      "Final Training Accuracy: 0.9896587133407593\n",
      "Final Validation Loss: 0.6976407766342163\n",
      "Final Validation Accuracy: 0.78152996301651\n",
      "Epoch 26: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.7756\n",
      "Layer: 3; Optimizer: RMSP; Batchsize: 50\n",
      "Final Training Loss: 0.041624195873737335\n",
      "Final Training Accuracy: 0.9941399693489075\n",
      "Final Validation Loss: 0.6998570561408997\n",
      "Final Validation Accuracy: 0.7780840992927551\n",
      "Epoch 40: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7305 - accuracy: 0.7789\n",
      "Layer: 3; Optimizer: RMSP; Batchsize: 100\n",
      "Final Training Loss: 0.03737400472164154\n",
      "Final Training Accuracy: 0.9937952160835266\n",
      "Final Validation Loss: 0.6588051319122314\n",
      "Final Validation Accuracy: 0.7904893159866333\n",
      "Epoch 42: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.7828\n",
      "Layer: 1; Optimizer: ADAM; Batchsize: 25\n",
      "Final Training Loss: 0.004273984115570784\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6347441077232361\n",
      "Final Validation Accuracy: 0.7856650352478027\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.7668\n",
      "Layer: 1; Optimizer: ADAM; Batchsize: 50\n",
      "Final Training Loss: 0.016244420781731606\n",
      "Final Training Accuracy: 1.0\n",
      "Final Validation Loss: 0.6465890407562256\n",
      "Final Validation Accuracy: 0.7842866778373718\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7696 - accuracy: 0.7607\n",
      "Layer: 1; Optimizer: ADAM; Batchsize: 100\n",
      "Final Training Loss: 0.08367861807346344\n",
      "Final Training Accuracy: 0.9994829297065735\n",
      "Final Validation Loss: 0.7196692824363708\n",
      "Final Validation Accuracy: 0.7780840992927551\n",
      "Epoch 23: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.7712\n",
      "Layer: 2; Optimizer: ADAM; Batchsize: 25\n",
      "Final Training Loss: 0.014742379076778889\n",
      "Final Training Accuracy: 0.9998276233673096\n",
      "Final Validation Loss: 0.6643669605255127\n",
      "Final Validation Accuracy: 0.7787732481956482\n",
      "Epoch 32: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.7740\n",
      "Layer: 2; Optimizer: ADAM; Batchsize: 50\n",
      "Final Training Loss: 0.019723471254110336\n",
      "Final Training Accuracy: 0.9998276233673096\n",
      "Final Validation Loss: 0.6496644616127014\n",
      "Final Validation Accuracy: 0.7849758863449097\n",
      "Epoch 47: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.7585\n",
      "Layer: 2; Optimizer: ADAM; Batchsize: 100\n",
      "Final Training Loss: 0.03295541927218437\n",
      "Final Training Accuracy: 0.9986211657524109\n",
      "Final Validation Loss: 0.6464458107948303\n",
      "Final Validation Accuracy: 0.78152996301651\n",
      "Epoch 17: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7631 - accuracy: 0.7679\n",
      "Layer: 3; Optimizer: ADAM; Batchsize: 25\n",
      "Final Training Loss: 0.05291895195841789\n",
      "Final Training Accuracy: 0.992933452129364\n",
      "Final Validation Loss: 0.6867592930793762\n",
      "Final Validation Accuracy: 0.7773948907852173\n",
      "Epoch 26: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7477 - accuracy: 0.7723\n",
      "Layer: 3; Optimizer: ADAM; Batchsize: 50\n",
      "Final Training Loss: 0.0422215536236763\n",
      "Final Training Accuracy: 0.9960358738899231\n",
      "Final Validation Loss: 0.6913554668426514\n",
      "Final Validation Accuracy: 0.7801516056060791\n",
      "Epoch 39: early stopping\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7417 - accuracy: 0.7696\n",
      "Layer: 3; Optimizer: ADAM; Batchsize: 100\n",
      "Final Training Loss: 0.0553027018904686\n",
      "Final Training Accuracy: 0.9910375475883484\n",
      "Final Validation Loss: 0.7095428109169006\n",
      "Final Validation Accuracy: 0.7718814611434937\n"
     ]
    }
   ],
   "source": [
    "# Tests with fourie transformation only\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fourie_pca, to_categorical(labels, num_classes=19), test_size=0.2, random_state=42)\n",
    "for opti in ['RMSP', 'ADAM']:\n",
    "    for i in range(3):\n",
    "        for bs in [25,50,100]:\n",
    "            title_appendix = f'layer{11-i}_optimizer={opti}_batchsize={bs}'\n",
    "            # Build the model\n",
    "            model = Sequential()\n",
    "            model.add(Dense(pow(2,10), activation='relu'))\n",
    "            model.add(Dropout(dor))\n",
    "            for x in range(i):\n",
    "                model.add(Dense(pow(2,10-(x+1)), activation='relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "            model.add(Dense(19, activation='softmax'))\n",
    "            optimizer=RMSprop(learning_rate=0.00005)\n",
    "            if opti == 'ADAM':\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "        \n",
    "            # Fit the model\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "            history = model.fit(X_train, y_train, epochs=50, batch_size=bs, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "        \n",
    "            # Evaluate the model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "            print('Layer: %.i; Optimizer: %s; Batchsize: %.i' % (i+1, opti, bs))\n",
    "            print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "            print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "            print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "            print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "            visualize_history(history, f'PCA_fourie_only_{title_appendix}_dens={i}_finacc={history.history[\"val_accuracy\"][-1]:.2f}')\n",
    "        \n",
    "            # Clear Keras session\n",
    "            K.clear_session()\n",
    "            del model\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060cea7-a9d8-41c4-8059-1269a2419ef5",
   "metadata": {},
   "source": [
    "Eine Genauigkeit von 80% scheint bei dieser Vorgehensweise nicht großartig übertroffen werden zu können. (Convolutional Neuronal Networks werden in einem anderen Notebook behandelt)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
