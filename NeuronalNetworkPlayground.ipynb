{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7ece40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 15:21:34.798559: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-04 15:21:34.798590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-04 15:21:34.799583: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-04 15:21:34.805539: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 15:21:35.549391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "from scipy.signal import butter, lfilter\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.activations import relu, tanh, linear\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from joblib import Parallel, delayed #Paralleize calculation\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, Column, Integer, ARRAY, MetaData, Table, Text\n",
    "from sqlalchemy.dialects.postgresql import ARRAY as PG_ARRAY\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# check if tensorflow uses GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1736a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom adapter function for postgre\n",
    "def adapt_numpy_ndarray(numpy_array):\n",
    "    return AsIs(list(numpy_array))\n",
    "# Register the postgre-adapter\n",
    "register_adapter(np.ndarray, adapt_numpy_ndarray)\n",
    "\n",
    "# Database connection parameters and alchemy engine\n",
    "dbname = 'bathunting'\n",
    "user = 'python'\n",
    "password = 'python_password'\n",
    "host = 'localhost'\n",
    "port = '5432' \n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}')\n",
    "\n",
    "# Functions to get data\n",
    "def get_target_data(target, limit=0, no_target=False):\n",
    "    lmt = \"\" if limit<=0 else f\"LIMIT {limit}\"\n",
    "    #query = \"\"\n",
    "    if no_target:\n",
    "        query = f\"SELECT new_arr FROM batcall where 10 < ANY(new_arr) and target = {target} {lmt}\"\n",
    "    else:\n",
    "        query = f\"SELECT target, new_arr FROM batcall where 10 < ANY(new_arr) and target = {target} {lmt}\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    if no_target:\n",
    "        df = pd.DataFrame(df['new_arr'].tolist())\n",
    "    return df\n",
    "\n",
    "# messy, i know\n",
    "def get_targets_to_data(limit=0):\n",
    "    lmt = \"\" if limit<=0 else f\"LIMIT {limit}\"\n",
    "    query = f\"SELECT target FROM batcall where 10 < ANY(new_arr) {lmt}\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df\n",
    "\n",
    "def get_all_data(targets=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], limit=0, no_target=False):\n",
    "    all_df = Parallel(n_jobs=-3, prefer=\"threads\")(delayed(get_target_data)(target, limit, no_target) for target in targets)\n",
    "    return all_df\n",
    "\n",
    "def get_data(targets=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], limit=0, no_target=False):\n",
    "    all_df = Parallel(n_jobs=-3, prefer=\"threads\")(delayed(get_target_data)(target, limit, no_target) for target in targets)\n",
    "    df = pd.concat(all_df)\n",
    "    return df\n",
    "\n",
    "# try to visualize only the maximum values per species\n",
    "def spectrogram_range(target):\n",
    "    df = get_target_data(target, limit=0, no_target=True)\n",
    "    max_vals = df.max()\n",
    "    min_vals = df.min()\n",
    "    \n",
    "    abs_pos = max_vals.abs()\n",
    "    abs_neg = min_vals.abs()\n",
    "    mask = (abs_pos > abs_neg).astype(bool)\n",
    "    return min_vals.where(mask, max_vals), max_vals.where(mask, min_vals)\n",
    "\n",
    "def get_targets():\n",
    "    #conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    #cursor = conn.cursor()\n",
    "    query = f\"SELECT target, bat FROM batcall group by target, bat order by target\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    #conn.close()\n",
    "    return df\n",
    "\n",
    "def get_shape(nested_list):\n",
    "    try:\n",
    "        # Initialize shape list\n",
    "        shape = []\n",
    "\n",
    "        # Iterate to calculate the shape\n",
    "        while isinstance(nested_list, list) or isinstance(nested_list, np.ndarray):\n",
    "            shape.append(len(nested_list))\n",
    "            nested_list = nested_list[0]\n",
    "\n",
    "        return tuple(shape)\n",
    "    except (TypeError, IndexError) as e:\n",
    "        # In case the nested lists are not uniformly sized\n",
    "        return f\"Irregular shape - nested lists are not of equal size. \\n ERROR: {e}\"\n",
    "    # Get data to work with\n",
    "def get_features_and_targets(limit=100, scaler=StandardScaler()):\n",
    "    data = get_data(limit=limit)\n",
    "\n",
    "    df = pd.DataFrame(data[\"new_arr\"].tolist())\n",
    "    if scaler != None:\n",
    "        df = scaler.fit_transform(df)\n",
    "\n",
    "    labels = pd.DataFrame(data[\"target\"])\n",
    "    labels = to_categorical(labels, num_classes=19)\n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96048d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "595309ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 19)\n",
      "(1900, 4410)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape\n",
    "df, labels = get_features_and_targets(limit=100, scaler=None) #limit=1000 is zu viel\n",
    "print(labels.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c470e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1520, 4410)\n",
      "(1520, 19)\n"
     ]
    }
   ],
   "source": [
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42)\n",
    "#X_train = X_train[:-13]\n",
    "#y_train = y_train[:-13]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0d248a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of input features\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(19, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87f5a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 15:48:14.338433: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 51.14MiB (rounded to 53625600)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-01-04 15:48:14.338484: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-01-04 15:48:14.338505: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 22, Chunks in use: 21. 5.5KiB allocated for chunks. 5.2KiB in use in bin. 420B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338520: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 3, Chunks in use: 3. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.2KiB client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338533: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.5KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338545: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338557: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338569: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338580: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338591: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338602: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338619: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 5, Chunks in use: 4. 858.2KiB allocated for chunks. 685.8KiB in use in bin. 629.6KiB client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338632: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0. 341.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338645: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 3, Chunks in use: 2. 2.19MiB allocated for chunks. 1.48MiB in use in bin. 1.48MiB client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338656: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338668: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338679: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338690: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338701: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338714: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 36.25MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338725: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338741: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338753: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-04 15:48:14.338767: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 51.14MiB was 32.00MiB, Chunk State: \n",
      "2024-01-04 15:48:14.338788: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 36.25MiB | Requested Size: 0B | in_use: 0 | bin_num: 17, prev:   Size: 978.8KiB | Requested Size: 978.6KiB | in_use: 1 | bin_num: -1\n",
      "2024-01-04 15:48:14.338798: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 41549824\n",
      "2024-01-04 15:48:14.338811: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000000 of size 256 next 1\n",
      "2024-01-04 15:48:14.338821: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000100 of size 1280 next 2\n",
      "2024-01-04 15:48:14.338831: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000600 of size 256 next 3\n",
      "2024-01-04 15:48:14.338840: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000700 of size 256 next 4\n",
      "2024-01-04 15:48:14.338849: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000800 of size 256 next 6\n",
      "2024-01-04 15:48:14.338873: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000900 of size 256 next 7\n",
      "2024-01-04 15:48:14.338877: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000a00 of size 256 next 5\n",
      "2024-01-04 15:48:14.338880: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000b00 of size 256 next 8\n",
      "2024-01-04 15:48:14.338884: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000c00 of size 256 next 12\n",
      "2024-01-04 15:48:14.338887: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000d00 of size 256 next 13\n",
      "2024-01-04 15:48:14.338891: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000e00 of size 256 next 11\n",
      "2024-01-04 15:48:14.338894: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116000f00 of size 256 next 14\n",
      "2024-01-04 15:48:14.338897: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116001000 of size 256 next 17\n",
      "2024-01-04 15:48:14.338901: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116001100 of size 256 next 19\n",
      "2024-01-04 15:48:14.338904: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116001200 of size 256 next 18\n",
      "2024-01-04 15:48:14.338908: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116001300 of size 256 next 25\n",
      "2024-01-04 15:48:14.338911: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116001400 of size 256 next 15\n",
      "2024-01-04 15:48:14.338915: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116001500 of size 768 next 16\n",
      "2024-01-04 15:48:14.338919: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f5116001800 of size 349952 next 9\n",
      "2024-01-04 15:48:14.338922: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116056f00 of size 176640 next 10\n",
      "2024-01-04 15:48:14.338926: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082100 of size 256 next 22\n",
      "2024-01-04 15:48:14.338929: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082200 of size 256 next 29\n",
      "2024-01-04 15:48:14.3"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust epochs and batch_size as needed\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38932: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f5116082300 of size 1280 next 27\n",
      "2024-01-04 15:48:14.338936: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082800 of size 768 next 28\n",
      "2024-01-04 15:48:14.338945: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082b00 of size 256 next 33\n",
      "2024-01-04 15:48:14.338949: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082c00 of size 256 next 30\n",
      "2024-01-04 15:48:14.338952: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082d00 of size 256 next 34\n",
      "2024-01-04 15:48:14.338956: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f5116082e00 of size 256 next 35\n",
      "2024-01-04 15:48:14.338959: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116082f00 of size 768 next 36\n",
      "2024-01-04 15:48:14.338963: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116083200 of size 172288 next 23\n",
      "2024-01-04 15:48:14.338966: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f51160ad300 of size 176640 next 24\n",
      "2024-01-04 15:48:14.338970: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f51160d8500 of size 550400 next 26\n",
      "2024-01-04 15:48:14.338973: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f511615eb00 of size 176640 next 32\n",
      "2024-01-04 15:48:14.338977: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f5116189d00 of size 176640 next 31\n",
      "2024-01-04 15:48:14.338980: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f51161b4f00 of size 747520 next 20\n",
      "2024-01-04 15:48:14.338984: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f511626b700 of size 1002240 next 21\n",
      "2024-01-04 15:48:14.338988: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f5116360200 of size 38010368 next 18446744073709551615\n",
      "2024-01-04 15:48:14.338992: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-01-04 15:48:14.338997: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 21 Chunks of size 256 totalling 5.2KiB\n",
      "2024-01-04 15:48:14.339002: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 768 totalling 2.2KiB\n",
      "2024-01-04 15:48:14.339006: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-01-04 15:48:14.339010: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 172288 totalling 168.2KiB\n",
      "2024-01-04 15:48:14.339014: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 176640 totalling 517.5KiB\n",
      "2024-01-04 15:48:14.339019: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 550400 totalling 537.5KiB\n",
      "2024-01-04 15:48:14.339023: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1002240 totalling 978.8KiB\n",
      "2024-01-04 15:48:14.339027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 2.16MiB\n",
      "2024-01-04 15:48:14.339032: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 41549824 memory_limit_: 41549824 available bytes: 0 curr_region_allocation_bytes_: 83099648\n",
      "2024-01-04 15:48:14.339039: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                        41549824\n",
      "InUse:                         2263808\n",
      "MaxInUse:                      3188736\n",
      "NumAllocs:                          63\n",
      "MaxAllocSize:                  1002240\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-01-04 15:48:14.339045: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] *****_***___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=20)  # Adjust epochs and batch_size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5aea332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 1s 1ms/step - loss: 2.1865 - accuracy: 0.4103\n",
      "Test Accuracy: 41.03\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7da76187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2713/2456465814.py:10: RuntimeWarning: divide by zero encountered in log10\n",
      "  stft = 10 * np.log10(stft)\n"
     ]
    }
   ],
   "source": [
    "data_reshaped = []\n",
    "for _,data in df.iterrows():\n",
    "    # Normalize\n",
    "    data -= np.mean(data)\n",
    "    data /= np.std(data)\n",
    "\n",
    "    # Realy no idea just assuming prof did it right\n",
    "    # Calculate spectrogram with FFT\n",
    "    stft = np.abs(librosa.stft(np.array(data), n_fft=512, hop_length=32))\n",
    "    stft = 10 * np.log10(stft)\n",
    "    stft = np.nan_to_num(stft)\n",
    "    # Scale between [0,1] and reduce shape if needed\n",
    "    stft = (stft - np.min(stft)) / (np.max(stft) - np.min(stft))\n",
    "    stft = np.reshape(stft, (257, 138, 1))\n",
    "    #stft = stft[:256, -128: , :]\n",
    "    data_reshaped.append(stft)\n",
    "df_reshaped = np.array(data_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61762c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=input_dim))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(19, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4959c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7cd15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 5ms/step - loss: 2.9402 - accuracy: 0.0419\n",
      "Test Accuracy: 4.19\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca1342",
   "metadata": {},
   "source": [
    " alles Mist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd53df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
