{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49759a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firefly-rgb/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "2024-01-08 14:27:17.553447: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-08 14:27:17.553573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-08 14:27:17.619462: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-08 14:27:17.752155: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-08 14:27:18.989142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:27:21.273826: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2024-01-08 14:27:21.273857: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: firefly-rgb-desktop\n",
      "2024-01-08 14:27:21.273863: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: firefly-rgb-desktop\n",
      "2024-01-08 14:27:21.273941: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 525.147.5\n",
      "2024-01-08 14:27:21.273958: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 545.23.8\n",
      "2024-01-08 14:27:21.273963: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 545.23.8 does not match DSO version 525.147.5 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import gc\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, lfilter\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.activations import relu, tanh, linear\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from joblib import Parallel, delayed #Paralleize calculation\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, Column, Integer, ARRAY, MetaData, Table, Text\n",
    "from sqlalchemy.dialects.postgresql import ARRAY as PG_ARRAY\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "# check if tensorflow uses GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851aac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom adapter function for postgre\n",
    "def adapt_numpy_ndarray(numpy_array):\n",
    "    return AsIs(list(numpy_array))\n",
    "# Register the postgre-adapter\n",
    "register_adapter(np.ndarray, adapt_numpy_ndarray)\n",
    "\n",
    "# Database connection parameters and alchemy engine\n",
    "dbname = 'bathunting'\n",
    "user = 'python'\n",
    "password = 'python_password'\n",
    "host = 'localhost'\n",
    "port = '5432' \n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}')\n",
    "\n",
    "# Functions to get datatf.compat.v1.reset_default_graph()  # Reset the TensorFlow graph\n",
    "\n",
    "def get_target_data(target, limit=0, no_target=False):\n",
    "    lmt = \"\" if limit<=0 else f\"LIMIT {limit}\"\n",
    "    #query = \"\"\n",
    "    if no_target:\n",
    "        query = f\"SELECT new_arr FROM batcall where 10 < ANY(new_arr) and target = {target} {lmt}\"\n",
    "    else:\n",
    "        query = f\"SELECT target, new_arr FROM batcall where 10 < ANY(new_arr) and target = {target} {lmt}\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    if no_target:\n",
    "        df = pd.DataFrame(df['new_arr'].tolist())\n",
    "    return df\n",
    "\n",
    "# messy, i know\n",
    "def get_targets_to_data(limit=0):\n",
    "    lmt = \"\" if limit<=0 else f\"LIMIT {limit}\"\n",
    "    query = f\"SELECT target FROM batcall where 10 < ANY(new_arr) {lmt}\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df\n",
    "\n",
    "def get_all_data(targets=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], limit=0, no_target=False):\n",
    "    all_df = Parallel(n_jobs=-3, prefer=\"threads\")(delayed(get_target_data)(target, limit, no_target) for target in targets)\n",
    "    return all_df\n",
    "\n",
    "def get_data(targets=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], limit=0, no_target=False):\n",
    "    all_df = Parallel(n_jobs=-3, prefer=\"threads\")(delayed(get_target_data)(target, limit, no_target) for target in targets)\n",
    "    df = pd.concat(all_df)\n",
    "    return df\n",
    "\n",
    "# try to visualize only the maximum values per species\n",
    "def spectrogram_range(target):\n",
    "    df = get_target_data(target, limit=0, no_target=True)\n",
    "    max_vals = df.max()\n",
    "    min_vals = df.min()\n",
    "    \n",
    "    abs_pos = max_vals.abs()\n",
    "    abs_neg = min_vals.abs()\n",
    "    mask = (abs_pos > abs_neg).astype(bool)\n",
    "    return min_vals.where(mask, max_vals), max_vals.where(mask, min_vals)\n",
    "\n",
    "def get_targets():\n",
    "    #conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    #cursor = conn.cursor()\n",
    "    query = f\"SELECT target, bat FROM batcall group by target, bat order by target\"\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    #conn.close()\n",
    "    return df\n",
    "\n",
    "def get_shape(nested_list):\n",
    "    try:\n",
    "        # Initialize shape list\n",
    "        shape = []\n",
    "\n",
    "        # Iterate to calculate the shape\n",
    "        while isinstance(nested_list, list) or isinstance(nested_list, np.ndarray):\n",
    "            shape.append(len(nested_list))\n",
    "            nested_list = nested_list[0]\n",
    "\n",
    "        return tuple(shape)\n",
    "    except (TypeError, IndexError) as e:\n",
    "        # In case the nested lists are not uniformly sized\n",
    "        return f\"Irregular shape - nested lists are not of equal size. \\n ERROR: {e}\"\n",
    "    \n",
    "# Get data to work with\n",
    "def get_features_and_targets(limit=100, scaler=StandardScaler(), categorical=True):\n",
    "    data = get_data(limit=limit)\n",
    "\n",
    "    df = pd.DataFrame(data[\"new_arr\"].tolist())\n",
    "    if scaler != None:\n",
    "        df = scaler.fit_transform(df)\n",
    "\n",
    "    labels = pd.DataFrame(data[\"target\"])\n",
    "    if categorical:\n",
    "        labels = to_categorical(labels, num_classes=19)\n",
    "    return df, labels\n",
    "\n",
    "def vogl_conversion(df):\n",
    "    data_reshaped = []\n",
    "    for _,data in df.iterrows():\n",
    "        # Normalize\n",
    "        data -= np.mean(data)\n",
    "        data /= np.std(data)\n",
    "\n",
    "        # Realy no idea just assuming prof did it right\n",
    "        # Calculate spectrogram with FFT\n",
    "        stft = np.abs(librosa.stft(np.array(data), n_fft=512, hop_length=32))\n",
    "        stft = 10 * np.log10(stft)\n",
    "        stft = np.nan_to_num(stft)\n",
    "        # Scale between [0,1] and reduce shape if needed\n",
    "        stft = (stft - np.min(stft)) / (np.max(stft) - np.min(stft))\n",
    "        stft = np.reshape(stft, (257, 138, 1))\n",
    "        stft = stft[:256, -128: , :]\n",
    "        data_reshaped.append(stft)\n",
    "    return np.array(data_reshaped)\n",
    "\n",
    "def confusion_matrix(model, X_test, y_test):\n",
    "    # Confusion Matrix\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_test, axis=1)  # y_test are the true labels (one-hot encoded)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Plot the confusion matrix using Seaborn\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db617238",
   "metadata": {},
   "source": [
    "This should be all about Convolutional Neuronal Networks and lowering the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ce4d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15776/4140194.py:102: RuntimeWarning: divide by zero encountered in log10\n",
      "  stft = 10 * np.log10(stft)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7250, 256, 128, 1)\n",
      "(7250, 19)\n"
     ]
    }
   ],
   "source": [
    "df, labels = get_features_and_targets(limit=500, scaler=None)\n",
    "df_reshaped = vogl_conversion(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_reshaped, labels, test_size=0.2, random_state=42)\n",
    "X_train = X_train[:-3]\n",
    "y_train = y_train[:-3]\n",
    "print(get_shape(X_train))\n",
    "print(get_shape(y_train))\n",
    "# Determine the number of input features\n",
    "input_dim = get_shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aae7cb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.config' has no attribute 'gpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m clear_session() \u001b[38;5;66;03m# clear keras session\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mreset_default_graph()  \u001b[38;5;66;03m# Reset the TensorFlow graph\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[38;5;241m.\u001b[39mset_per_process_memory_fraction(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.config' has no attribute 'gpu'"
     ]
    }
   ],
   "source": [
    "# Density 10 to 500 \n",
    "for i in range(10, 501, 10):\n",
    "    clear_session() # clear keras session\n",
    "    tf.compat.v1.reset_default_graph()  # Reset the TensorFlow graph\n",
    "    tf.config.gpu.set_per_process_memory_fraction(0.5)\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(256,128,1)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(i, activation='relu'))\n",
    "    model.add(Dense(19, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(learning_rate=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Density: %.i' % (i))\n",
    "    print(f\"Final Training Loss: {history.history['loss'][-1]}\")\n",
    "    print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "    print(f\"Final Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "    print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "    print('Test Accuracy: %.2f %%' % (accuracy*100))\n",
    "    print('Test Loss: %.2f' % (loss))\n",
    "    \n",
    "    # Free Memory for following models\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.compat.v1.reset_default_graph()  # Reset the TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85848c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
